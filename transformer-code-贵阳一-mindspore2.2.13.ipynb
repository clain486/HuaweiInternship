{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86c3ef0c",
   "metadata": {},
   "source": [
    "# Transformer实现“德译英”翻译\n",
    "\n",
    "## 前言\n",
    "<br>\n",
    "<div style=\"display: flex; align-items: left;\">\n",
    "    <div style=\"flex: 1;\">\n",
    "Transformer是一种基于注意力机制结构的神经网络，由Vaswani等人在2017年的论文“Attention Is All You Need”中提出，用于处理机器翻译、语言建模和文本生成等自然语言处理任务。\n",
    "\n",
    "Transformer与传统NLP特征提取类模型的区别主要在以下两点：\n",
    "- Transformer将自注意力机制和多头注意力机制的概念运用到模型中；\n",
    "- 由于缺少RNN模型的时序性，Transformer引入了位置编码，在数据上而非模型中添加位置信息；\n",
    "\n",
    "以上的处理带来了2个优点：\n",
    "- 更容易并行化，训练更加高效；\n",
    "- 在处理长序列的任务中表现优秀，可以快速捕捉长距离中的关联信息。\n",
    "\n",
    "<br><br>\n",
    "Transformer的模型结构由**编码器Encoder**和**解码器Decoder**组成，整体结构图如右图所示。\n",
    "        \n",
    "本文将从数据处理开始，顺序介绍embedding、位置编码、编码器、解码器的原理及代码实现，最后介绍网络训练和推理部分。\n",
    "<br><br><br>\n",
    "在执行代码前需要准备MindSpore环境，安装依赖包："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07717dbd-df48-4166-9392-51057ed97545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Processing ./mindspore-2.2.13-cp39-cp39-linux_aarch64.whl\n",
      "Requirement already satisfied: psutil>=5.6.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.2.13) (5.9.5)\n",
      "Requirement already satisfied: scipy>=1.5.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.2.13) (1.10.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.2.13) (10.0.1)\n",
      "Requirement already satisfied: asttokens>=2.0.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.2.13) (2.4.1)\n",
      "Requirement already satisfied: protobuf>=3.13.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.2.13) (3.20.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.2.13) (1.22.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.2.13) (23.2)\n",
      "Requirement already satisfied: astunparse>=1.6.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.2.13) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from asttokens>=2.0.4->mindspore==2.2.13) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from astunparse>=1.6.3->mindspore==2.2.13) (0.38.4)\n",
      "Installing collected packages: mindspore\n",
      "  Attempting uninstall: mindspore\n",
      "    Found existing installation: mindspore 2.2.0\n",
      "    Uninstalling mindspore-2.2.0:\n",
      "      Successfully uninstalled mindspore-2.2.0\n",
      "Successfully installed mindspore-2.2.13\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/MindSpore/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mindspore-2.2.13-cp39-cp39-linux_aarch64.whl --trusted-host ms-release.obs.cn-north-4.myhuaweicloud.com -i https://pypi.tuna.tsinghua.edu.cn/simple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "706f9a28-71f8-4a31-9004-35be01de49c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                                  Version\n",
      "---------------------------------------- -------------------------\n",
      "absl-py                                  0.13.0\n",
      "aclruntime                               0.0.2\n",
      "addict                                   2.4.0\n",
      "aiofiles                                 23.2.1\n",
      "ais-bench                                0.0.2\n",
      "ait                                      0.0.1\n",
      "akg                                      2.1\n",
      "albumentations                           1.3.1\n",
      "altair                                   5.2.0\n",
      "anyio                                    4.2.0\n",
      "APScheduler                              3.9.1\n",
      "arrow                                    1.2.3\n",
      "asgiref                                  3.7.2\n",
      "astroid                                  2.11.7\n",
      "asttokens                                2.4.1\n",
      "astunparse                               1.6.3\n",
      "attrs                                    23.2.0\n",
      "auto-optimizer                           0.1.0\n",
      "auto-tune                                0.1.0\n",
      "backports.zoneinfo                       0.2.1\n",
      "binaryornot                              0.4.4\n",
      "blinker                                  1.7.0\n",
      "blosc2                                   2.0.0\n",
      "boto3                                    1.12.22\n",
      "botocore                                 1.15.49\n",
      "certifi                                  2023.11.17\n",
      "cffi                                     1.15.1.post20230728144220\n",
      "chardet                                  3.0.4\n",
      "charset-normalizer                       2.0.12\n",
      "click                                    8.1.7\n",
      "click-aliases                            1.0.4\n",
      "cloudpickle                              1.3.0\n",
      "colorama                                 0.4.4\n",
      "coloredlogs                              15.0.1\n",
      "compare                                  0.0.2\n",
      "configparser                             5.2.0\n",
      "cookiecutter                             2.5.0\n",
      "coverage                                 6.4.3\n",
      "cryptography                             3.4.7\n",
      "cycler                                   0.12.1\n",
      "Cython                                   3.0.2\n",
      "dask                                     2.18.1\n",
      "dataflow                                 0.0.1\n",
      "debugpy                                  1.8.0\n",
      "decorator                                4.4.1\n",
      "defusedxml                               0.7.1\n",
      "dill                                     0.3.7\n",
      "Django                                   4.2.8\n",
      "docutils                                 0.15.2\n",
      "easydict                                 1.9\n",
      "entrypoints                              0.4\n",
      "ephemeral-port-reserve                   1.1.4\n",
      "esdk-obs-python                          3.20.1\n",
      "et-xmlfile                               1.1.0\n",
      "exceptiongroup                           1.2.0\n",
      "executing                                2.0.1\n",
      "fastapi                                  0.108.0\n",
      "ffmpy                                    0.3.1\n",
      "filelock                                 3.13.1\n",
      "flask                                    2.3.3\n",
      "Flask-Cors                               4.0.0\n",
      "flatbuffers                              23.5.26\n",
      "fonttools                                4.47.0\n",
      "fsspec                                   2023.12.2\n",
      "ftfy                                     6.1.3\n",
      "gast                                     0.3.2\n",
      "gnureadline                              8.1.2\n",
      "gradio                                   3.50.2\n",
      "gradio-client                            0.6.1\n",
      "grpcio                                   1.58.0\n",
      "grpcio-tools                             1.58.0\n",
      "gunicorn                                 21.2.0\n",
      "h11                                      0.14.0\n",
      "h5py                                     3.9.0\n",
      "hccl                                     0.1.0\n",
      "hccl-parser                              0.1\n",
      "httpcore                                 1.0.2\n",
      "httpx                                    0.26.0\n",
      "huaweicloud-sdk-python-modelarts-dataset 0.1.5\n",
      "huaweicloudsdkcore                       3.1.8\n",
      "huaweicloudsdkcsms                       3.1.8\n",
      "huggingface-hub                          0.20.1\n",
      "humanfriendly                            10.0\n",
      "idna                                     2.10\n",
      "image                                    1.5.28\n",
      "imageio                                  2.33.1\n",
      "imgaug                                   0.4.0\n",
      "importlib-metadata                       7.0.1\n",
      "importlib-resources                      6.1.1\n",
      "iniconfig                                2.0.0\n",
      "ipykernel                                6.7.0\n",
      "ipython                                  8.18.1\n",
      "isort                                    5.13.2\n",
      "itsdangerous                             2.1.2\n",
      "jdcal                                    1.4.1\n",
      "jedi                                     0.19.1\n",
      "jieba                                    0.42.1\n",
      "Jinja2                                   3.1.2\n",
      "jmespath                                 0.10.0\n",
      "joblib                                   1.3.2\n",
      "jsonschema                               4.20.0\n",
      "jsonschema-specifications                2023.12.1\n",
      "jupyter-client                           7.4.9\n",
      "jupyter-core                             5.6.0\n",
      "Keras                                    2.3.1\n",
      "Keras-Applications                       1.0.8\n",
      "Keras-Preprocessing                      1.1.2\n",
      "kfac                                     0.2.0\n",
      "kiwisolver                               1.4.5\n",
      "latex2mathml                             3.77.0\n",
      "lazy-import                              0.2.2\n",
      "lazy-loader                              0.3\n",
      "lazy-object-proxy                        1.10.0\n",
      "libcst                                   0.4.7\n",
      "llvmlite                                 0.40.1\n",
      "lxml                                     4.9.3\n",
      "ma-cau                                   1.1.7\n",
      "ma-cau-adapter                           1.1.3\n",
      "ma-cli                                   1.2.3\n",
      "Markdown                                 3.5.1\n",
      "markdown-it-py                           3.0.0\n",
      "MarkupSafe                               2.1.3\n",
      "marshmallow                              3.20.1\n",
      "matplotlib                               3.5.1\n",
      "matplotlib-inline                        0.1.6\n",
      "mccabe                                   0.7.0\n",
      "mdtex2html                               1.2.0\n",
      "mdurl                                    0.1.2\n",
      "mindarmour                               2.0.0\n",
      "mindformers                              0.8.0\n",
      "mindinsight                              2.2.0\n",
      "mindpet                                  1.0.1\n",
      "mindspore                                2.2.13\n",
      "mindspore-lite                           2.2.0\n",
      "mindx-elastic                            0.0.1\n",
      "mmcv                                     2.0.1\n",
      "mmengine                                 0.10.2\n",
      "mock                                     4.0.3\n",
      "modelarts                                1.4.20\n",
      "modelarts-mindspore-model-server         1.0.6\n",
      "moxing-framework                         2.2.3.2c7f2141\n",
      "mpmath                                   1.3.0\n",
      "msadvisor                                1.0.0\n",
      "msgpack                                  1.0.7\n",
      "mypy-extensions                          1.0.0\n",
      "nest-asyncio                             1.5.8\n",
      "networkx                                 3.2.1\n",
      "nltk                                     3.8.1\n",
      "npu-bridge                               1.15.0\n",
      "npu-device                               0.1\n",
      "numba                                    0.57.1\n",
      "numexpr                                  2.8.6\n",
      "numpy                                    1.22.0\n",
      "onnx                                     1.15.0\n",
      "onnxconverter-common                     1.14.0\n",
      "onnxruntime                              1.15.1\n",
      "op-compile-tool                          0.1.0\n",
      "op-gen                                   0.1\n",
      "op-test-frame                            0.1\n",
      "opc-tool                                 0.1.0\n",
      "opencv-python                            4.8.0.76\n",
      "opencv-python-headless                   4.9.0.80\n",
      "openpyxl                                 3.0.3\n",
      "orjson                                   3.9.10\n",
      "packaging                                23.2\n",
      "pandas                                   1.3.5\n",
      "parso                                    0.8.3\n",
      "pathlib2                                 2.3.7.post1\n",
      "pexpect                                  4.9.0\n",
      "Pillow                                   10.0.1\n",
      "pip                                      21.0.1\n",
      "platformdirs                             4.1.0\n",
      "pluggy                                   1.3.0\n",
      "prettytable                              3.9.0\n",
      "prometheus-client                        0.8.0\n",
      "prompt-toolkit                           3.0.43\n",
      "protobuf                                 3.20.2\n",
      "psutil                                   5.9.5\n",
      "ptyprocess                               0.7.0\n",
      "pure-eval                                0.2.2\n",
      "py                                       1.11.0\n",
      "py-cpuinfo                               9.0.0\n",
      "pycocotools                              2.0.7\n",
      "pycparser                                2.21\n",
      "pydantic                                 1.10.11\n",
      "pydub                                    0.25.1\n",
      "pygments                                 2.17.2\n",
      "pylint                                   2.14.5\n",
      "pyparsing                                3.1.1\n",
      "pypng                                    0.20220715.0\n",
      "pytest                                   7.1.2\n",
      "python-dateutil                          2.8.2\n",
      "python-multipart                         0.0.6\n",
      "python-slugify                           8.0.1\n",
      "pytz                                     2023.3.post1\n",
      "PyWavelets                               1.4.1\n",
      "PyYAML                                   6.0.1\n",
      "pyzmq                                    25.1.2\n",
      "qudida                                   0.0.4\n",
      "referencing                              0.32.0\n",
      "regex                                    2023.12.25\n",
      "requests                                 2.27.1\n",
      "requests-futures                         1.0.0\n",
      "requests-toolbelt                        0.10.1\n",
      "rich                                     13.7.0\n",
      "rouge-chinese                            1.0.3\n",
      "rpds-py                                  0.16.2\n",
      "s3transfer                               0.3.7\n",
      "schedule-search                          0.0.1\n",
      "scikit-image                             0.21.0\n",
      "scikit-learn                             1.0.2\n",
      "scikit-video                             1.1.11\n",
      "scipy                                    1.10.1\n",
      "semantic-version                         2.10.0\n",
      "sentencepiece                            0.1.99\n",
      "setuptools                               65.5.1\n",
      "shapely                                  2.0.2\n",
      "simplejson                               3.17.0\n",
      "six                                      1.16.0\n",
      "skl2onnx                                 1.16.0\n",
      "sniffio                                  1.3.0\n",
      "sqlparse                                 0.4.4\n",
      "stack-data                               0.6.3\n",
      "starlette                                0.32.0.post1\n",
      "sympy                                    1.4\n",
      "synr                                     0.5.0\n",
      "tables                                   3.8.0\n",
      "tabulate                                 0.8.9\n",
      "tailor                                   0.3.2\n",
      "te                                       0.4.0\n",
      "tenacity                                 8.1.0\n",
      "tensorflow-probability                   0.10.1\n",
      "termcolor                                2.4.0\n",
      "terminaltables                           3.1.0\n",
      "text-unidecode                           1.3\n",
      "threadpoolctl                            3.2.0\n",
      "tifffile                                 2023.12.9\n",
      "toml                                     0.10.1\n",
      "tomli                                    2.0.1\n",
      "tomlkit                                  0.12.3\n",
      "toolz                                    0.12.0\n",
      "tornado                                  6.4\n",
      "tqdm                                     4.66.1\n",
      "traitlets                                5.14.0\n",
      "treelib                                  1.7.0\n",
      "typing-extensions                        4.9.0\n",
      "typing-inspect                           0.9.0\n",
      "tzlocal                                  5.1\n",
      "umap-learn-modified                      0.3.8\n",
      "urllib3                                  1.26.7\n",
      "uvicorn                                  0.25.0\n",
      "wcwidth                                  0.2.12\n",
      "websockets                               11.0.3\n",
      "werkzeug                                 3.0.1\n",
      "wheel                                    0.38.4\n",
      "wrapt                                    1.16.0\n",
      "xlrd                                     1.2.0\n",
      "XlsxWriter                               3.1.9\n",
      "xmltodict                                0.12.0\n",
      "yapf                                     0.40.2\n",
      "zipp                                     3.17.0\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/MindSpore/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "812619d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting download\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/37/45/01e7455a9659528e77a414b222326d4c525796e4f571bbabcb2e0ff3d1f4/download-0.3.5-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: nltk in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (3.8.1)\n",
      "Requirement already satisfied: requests in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from download) (2.27.1)\n",
      "Requirement already satisfied: six in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from download) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from download) (4.66.1)\n",
      "Requirement already satisfied: click in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->download) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->download) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->download) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->download) (2.10)\n",
      "Installing collected packages: download\n",
      "Successfully installed download-0.3.5\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/MindSpore/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install download nltk -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579f55c6",
   "metadata": {},
   "source": [
    "## 数据处理\n",
    "\n",
    "### 数据集下载\n",
    "\n",
    "我们本次使用的数据集为**Multi30K数据集**，它是一个大规模的图像-文本数据集，包含30K+图片，每张图片都有对应的德文和英文的文本描述。\n",
    "\n",
    "在本次文本翻译任务中，德语是源语言（source languag），英语是目标语言（target language），运行下面的代码下载并展示数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "526fa567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://modelscope.cn/api/v1/datasets/SelinaRR/Multi30K/repo?Revision=master&FilePath=Multi30K.zip (1 byte)\n",
      "\n",
      "file_sizes: 1.37MB [00:00, 4.91MB/s]                                            \n",
      "Extracting zip file...\n",
      "Successfully downloaded / unzipped to ./\n",
      "========================================datasets in ./datasets/train/train.de========================================\n",
      "0 Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\n",
      "1 Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.\n",
      "2 Ein kleines Mädchen klettert in ein Spielhaus aus Holz.\n",
      "3 Ein Mann in einem blauen Hemd steht auf einer Leiter und putzt ein Fenster.\n",
      "4 Zwei Männer stehen am Herd und bereiten Essen zu.\n",
      "========================================datasets in ./datasets/train/train.en========================================\n",
      "0 Two young, White males are outside near many bushes.\n",
      "1 Several men in hard hats are operating a giant pulley system.\n",
      "2 A little girl climbing into a wooden playhouse.\n",
      "3 A man in a blue shirt is standing on a ladder cleaning a window.\n",
      "4 Two men are at the stove preparing food.\n"
     ]
    }
   ],
   "source": [
    "from download import download\n",
    "import re\n",
    "\n",
    "url = \"https://modelscope.cn/api/v1/datasets/SelinaRR/Multi30K/repo?Revision=master&FilePath=Multi30K.zip\"\n",
    "\n",
    "download(url, './', kind='zip', replace=True)\n",
    "\n",
    "datasets_path = './datasets/'\n",
    "train_path = datasets_path + 'train/'\n",
    "valid_path = datasets_path + 'valid/'\n",
    "test_path = datasets_path + 'test/'\n",
    "\n",
    "def print_data(data_file_path, print_n=5):\n",
    "    print(\"=\" * 40 + \"datasets in {}\".format(data_file_path) + \"=\" * 40)\n",
    "    with open(data_file_path, 'r', encoding='utf-8') as en_file:\n",
    "        en = en_file.readlines()[:print_n]\n",
    "        for index, seq in enumerate(en):\n",
    "            print(index, seq.replace('\\n', ''))\n",
    "\n",
    "\n",
    "print_data(train_path + 'train.de')\n",
    "print_data(train_path + 'train.en')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a8afdc",
   "metadata": {},
   "source": [
    "### 数据集读取\n",
    "\n",
    "在使用数据进行模型训练等操作时，我们需要对数据进行预处理，流程如下：\n",
    "\n",
    "1. 加载数据集；\n",
    "2. 构建词典；\n",
    "3. 创建数据迭代器；\n",
    "\n",
    "加载数据集，并进行分词，即将句子拆解为单独的词元（token，可以为字符或者单词）。一般在机器翻译类任务中，我们习惯进行单词级词元化，即每个词元要么为一个单词，要么为一个标点符号。同一个单词，不论首字母是否大写，都应该对应同一个词元，故在分词前，我们需统一将单词转换为小写。\n",
    "\n",
    "```text\n",
    "\"Hello world!\" --> [\"hello\", \"world\", \"!\"]\n",
    "```\n",
    "\n",
    "接下来，我们创建数据加载器`Multi30K`。后期调用该类进行遍历时，每次返回当前源语言（德语）与目标语言（英语）文本描述的词元列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bef9608a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "德文：['zwei', 'junge', 'weiße', 'männer', 'sind', 'im', 'freien', 'in', 'der', 'nähe', 'vieler', 'büsche', '.']\n",
      "英文：['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "class Multi30K():\n",
    "    \"\"\"Multi30K数据集加载器，加载Multi30K数据集并处理为一个Python迭代对象\"\"\"\n",
    "    def __init__(self, path):\n",
    "        self.data = self._load(path)\n",
    "\n",
    "    def _load(self, path):\n",
    "        def tokenize(text):\n",
    "            text = text.rstrip()\n",
    "            return [tok.lower() for tok in re.findall(r'\\w+|[^\\w\\s]', text)]\n",
    "        \n",
    "        def read_data(data_file_path):\n",
    "            with open(data_file_path, 'r', encoding='utf-8') as data_file:\n",
    "                data = data_file.readlines()[:-1]\n",
    "                return [tokenize(i) for i in data]\n",
    "\n",
    "        members = {i.split('.')[-1]: path + i for i in os.listdir(path)}\n",
    "        ret = [read_data(members['de']), read_data(members['en'])]\n",
    "        return list(zip(*ret))\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = Multi30K(train_path), Multi30K(valid_path), Multi30K(test_path)\n",
    "\n",
    "for de, en in train_dataset:\n",
    "    print(f'德文：{de}')\n",
    "    print(f'英文：{en}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7ab295",
   "metadata": {},
   "source": [
    "### 构建词典\n",
    "\n",
    "将每个词元映射到从0开始的数字索引中（为节约存储空间，可过滤掉词频低的词元），词元和数字索引所构成的集合叫做词典（vocabulary）。\n",
    "\n",
    "以上述“Hello world!”为例，该序列组成的词典为：\n",
    "\n",
    "```text\n",
    "{\"<unk>\": 0, \"<pad>\": 1, \"<bos>\": 2, \"<eos>\": 3, \"hello\": 4, \"world\": 5, \"!\": 6}\n",
    "```\n",
    "\n",
    "在构建词典中，我们使用了4个特殊词元。\n",
    "\n",
    "- `<unk>`：未知词元（unknown），将出现次数少于一定频率的单词统一判定为未知词元；\n",
    "- `<bos>`：起始词元（begin of sentence），用来标注一个句子的开始；\n",
    "- `<eos>`：结束词元（end of sentence），用来标注一个句子的结束；\n",
    "- `<pad>`：填充词元（padding），当句子长度不够时将句子填充至统一长度；\n",
    "\n",
    "通过`Vocab`创建词典后，我们可以实现词元与数字索引之间的互相转换。我们可以通过调用`enocde`函数，获取输入词元对应的数字索引，通过调用`decode`函数，获取输入数字索引对应的词元。同样，我们也可以完成词元列表和数字索引列表之间的转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b242929",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    \"\"\"通过词频字典，构建词典\"\"\"\n",
    "\n",
    "    special_tokens = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "    def __init__(self, word_count_dict, min_freq=1):\n",
    "        self.word2idx = {}\n",
    "        for idx, tok in enumerate(self.special_tokens):\n",
    "            self.word2idx[tok] = idx\n",
    "\n",
    "        filted_dict = {w: c for w, c in word_count_dict.items() if c >= min_freq}\n",
    "        for w, _ in filted_dict.items():\n",
    "            self.word2idx[w] = len(self.word2idx)\n",
    "\n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "\n",
    "        self.bos_idx = self.word2idx['<bos>']\n",
    "        self.eos_idx = self.word2idx['<eos>']\n",
    "        self.pad_idx = self.word2idx['<pad>']\n",
    "        self.unk_idx = self.word2idx['<unk>']\n",
    "\n",
    "    def _word2idx(self, word):\n",
    "        \"\"\"单词映射至数字索引\"\"\"\n",
    "        if word not in self.word2idx:\n",
    "            return self.unk_idx\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def _idx2word(self, idx):\n",
    "        \"\"\"数字索引映射至单词\"\"\"\n",
    "        if idx not in self.idx2word:\n",
    "            raise ValueError('input index is not in vocabulary.')\n",
    "        return self.idx2word[idx]\n",
    "\n",
    "    def encode(self, word_or_list):\n",
    "        \"\"\"将单个单词或单词数组映射至单个数字索引或数字索引数组\"\"\"\n",
    "        if isinstance(word_or_list, list):\n",
    "            return [self._word2idx(i) for i in word_or_list]\n",
    "        return self._word2idx(word_or_list)\n",
    "\n",
    "    def decode(self, idx_or_list):\n",
    "        \"\"\"将单个数字索引或数字索引数组映射至单个单词或单词数组\"\"\"\n",
    "        if isinstance(idx_or_list, list):\n",
    "            return [self._idx2word(i) for i in idx_or_list]\n",
    "        return self._idx2word(idx_or_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb4feae",
   "metadata": {},
   "source": [
    "使用`collections`中的`Counter`和`OrderedDict`统计英/德语每个单词在整体文本中出现的频率。构建词频字典，然后再将词频字典转为词典。其中，收录所有源语言（德语）词元的词典为`de_vocab`，收录所有目标语言（英语）词元的词典为`en_vocab`。\n",
    "\n",
    "在分配数字索引时有一个小技巧：常用的词元对应数值较小的索引，这样可以节约检索时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb0c0e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in de vocabulary:7882 and en vocabulary:5898\n",
      "\n",
      "word:['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']\n",
      "index:[16, 24, 15, 25, 776, 17, 57, 80, 204, 1305, 5]\n",
      "\n",
      "index:[5, 6, 7, 8, 9, 10]\n",
      "word:['.', 'in', 'the', 'on', 'man', 'is']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "\n",
    "def build_vocab(dataset):\n",
    "    de_words, en_words = [], []\n",
    "    for de, en in dataset:\n",
    "        de_words.extend(de)\n",
    "        en_words.extend(en)\n",
    "    \n",
    "    de_count_dict = OrderedDict(sorted(Counter(de_words).items(), key=lambda t: t[1], reverse=True))\n",
    "    en_count_dict = OrderedDict(sorted(Counter(en_words).items(), key=lambda t: t[1], reverse=True))\n",
    "\n",
    "    return Vocab(de_count_dict, min_freq=2), Vocab(en_count_dict, min_freq=2)\n",
    "\n",
    "de_vocab, en_vocab = build_vocab(train_dataset)\n",
    "print('Unique tokens in de vocabulary:{} and en vocabulary:{}\\n'.format(len(de_vocab), len(en_vocab)))\n",
    "\n",
    "str_seq_en = ['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']\n",
    "print(\"word:{}\\nindex:{}\\n\".format(str_seq_en, en_vocab.encode(str_seq_en)))\n",
    "\n",
    "index = [5, 6, 7, 8, 9, 10]\n",
    "print(\"index:{}\\nword:{}\".format(index, en_vocab.decode(index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0093649d",
   "metadata": {},
   "source": [
    "从上面的打印可以看出，我们完成了从词元到索引、从索引到词元之间的转换。\n",
    "\n",
    "### 数据迭代器\n",
    "\n",
    "数据处理的最后一步是创建数据迭代器。截至目前，我们已经通过数据加载器`Multi30K`将源语言（德语）与目标语言（英语）的文本描述转换为词元序列，并构建了词元与数字索引一一对应的词典，接下来，需要将词元序列转换为数字索引序列。\n",
    "\n",
    "还是以“Hello world!”为例，我们逐步演示数据迭代器中的操作\n",
    "\n",
    "1. 我们将表示开始和结束的特殊词元`<bos>`和`<eos>`分别添加在每个词元序列的句首和句尾。\n",
    "\n",
    "```text\n",
    "处理前：[\"hello\", \"world\", \"!\"]\n",
    "处理后：[\"<bos>\", \"hello\", \"world\", \"!\", \"<eos>\"]\n",
    "```\n",
    "\n",
    "2. 统一序列长度（超出长度的进行截断，未达到长度的通过填充`<pad>`进行补齐）,同时记录序列的有效长度。此处假定统一的长度为7。\n",
    "\n",
    "```text\n",
    "处理前：[\"<bos>\", \"hello\", \"world\", \"!\", \"<eos>\"]\n",
    "处理后：[\"<bos>\", \"hello\", \"world\", \"!\", \"<eos>\", \"<pad>\", \"<pad>\"]， valid length = 5\n",
    "```\n",
    "\n",
    "3. 最后，对文本序列进行批处理。对于每个batch中的序列，通过调用词典中的`encode`为序列中的所有词元找到其对应的数字索引，将结果以`Tensor`的形式返回。\n",
    "\n",
    "```text\n",
    "处理前：[\"<bos>\", \"hello\", \"world\", \"!\", \"<eos>\", \"<pad>\", \"<pad>\"]\n",
    "处理后：Tensor([2, 4, 5, 6, 3, 1, 1])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e3d3241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:23:34.718.370 [mindspore/run_check/_check_version.py:357] MindSpore version 2.2.13 and Ascend AI software package (Ascend Data Center Solution)version 7.0 does not match, the version of software package expect one of ['7.1']. Please refer to the match info on: https://www.mindspore.cn/install\n",
      "/usr/local/Ascend/ascend-toolkit/7.0.RC1/python/site-packages/tbe/tvm/contrib/ccec.py:766: DeprecationWarning: invalid escape sequence \\L\n",
      "  if not dirpath.find(\"AppData\\Local\\Temp\"):\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/classifier/transdata/transdata_classifier.py:222: DeprecationWarning: invalid escape sequence \\B\n",
      "  \"\"\"\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/vector/transdata/common/graph/transdata_graph_info.py:140: DeprecationWarning: invalid escape sequence \\c\n",
      "  \"\"\"\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:23:41.889.040 [mindspore/run_check/_check_version.py:375] MindSpore version 2.2.13 and \"te\" wheel package version 7.0 does not match. For details, refer to the installation guidelines: https://www.mindspore.cn/install\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:23:41.893.031 [mindspore/run_check/_check_version.py:382] MindSpore version 2.2.13 and \"hccl\" wheel package version 7.0 does not match. For details, refer to the installation guidelines: https://www.mindspore.cn/install\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:23:41.894.102 [mindspore/run_check/_check_version.py:396] Please pay attention to the above warning, countdown: 3\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:23:42.896.019 [mindspore/run_check/_check_version.py:396] Please pay attention to the above warning, countdown: 2\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:23:43.898.503 [mindspore/run_check/_check_version.py:396] Please pay attention to the above warning, countdown: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_idx.shape:(128, 32)\n",
      "[[ 2  5 13 ...  1  1  1]\n",
      " [ 2  5 13 ...  1  1  1]\n",
      " [ 2  5 13 ...  1  1  1]\n",
      " ...\n",
      " [ 2  5 52 ...  1  1  1]\n",
      " [ 2  8 37 ...  1  1  1]\n",
      " [ 2  5 33 ...  1  1  1]]\n",
      "src_len.shape:(128,)\n",
      "[27 25 24 24 23 23 23 23 22 22 22 21 21 21 21 21 20 20 20 20 20 19 19 19\n",
      " 18 18 18 18 18 18 18 18 17 17 17 17 17 17 17 17 17 17 16 16 16 16 16 16\n",
      " 16 16 16 16 15 15 15 15 15 15 15 15 15 15 15 14 14 14 14 14 14 14 14 14\n",
      " 14 14 14 14 13 13 13 13 13 13 13 13 13 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12 12 12 11 11 11 11 11 11 11 11 11 11 10 10 10 10 10 10\n",
      " 10  9  9  9  9  9  9  8]\n",
      "trg_idx.shape:(128, 32)\n",
      "[[   2    4 2243 ...    1    1    1]\n",
      " [   2    4    9 ...    1    1    1]\n",
      " [   2    4    9 ...    1    1    1]\n",
      " ...\n",
      " [   2    4   55 ...    1    1    1]\n",
      " [   2    4   38 ...    1    1    1]\n",
      " [   2    4   35 ...    1    1    1]]\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "\n",
    "class Iterator():\n",
    "    \"\"\"创建数据迭代器\"\"\"\n",
    "    def __init__(self, dataset, de_vocab, en_vocab, batch_size, max_len=32, drop_reminder=False):\n",
    "        self.dataset = dataset\n",
    "        self.de_vocab = de_vocab\n",
    "        self.en_vocab = en_vocab\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.max_len = max_len\n",
    "        self.drop_reminder = drop_reminder\n",
    "\n",
    "        length = len(self.dataset) // batch_size\n",
    "        self.len = length if drop_reminder else length + 1  # 批量数量\n",
    "\n",
    "    def __call__(self):\n",
    "        def pad(idx_list, vocab, max_len):\n",
    "            \"\"\"统一序列长度，并记录有效长度\"\"\"\n",
    "            idx_pad_list, idx_len = [], []\n",
    "            for i in idx_list:\n",
    "                if len(i) > max_len - 2:\n",
    "                    idx_pad_list.append([vocab.bos_idx] + i[:max_len-2] + [vocab.eos_idx])\n",
    "                    idx_len.append(max_len)\n",
    "                else:\n",
    "                    idx_pad_list.append([vocab.bos_idx] + i + [vocab.eos_idx] + [vocab.pad_idx] * (max_len - len(i) - 2))\n",
    "                    idx_len.append(len(i) + 2)\n",
    "            return idx_pad_list, idx_len\n",
    "\n",
    "        def sort_by_length(src, trg):\n",
    "            \"\"\"根据src的字段长度进行排序\"\"\"\n",
    "            data = zip(src, trg)\n",
    "            data = sorted(data, key=lambda t: len(t[0]), reverse=True)\n",
    "            return zip(*list(data))\n",
    "\n",
    "        def encode_and_pad(batch_data, max_len):\n",
    "            \"\"\"将批量中的文本数据转换为数字索引，并统一每个序列的长度\"\"\"\n",
    "            src_data, trg_data = zip(*batch_data)\n",
    "            src_idx = [self.de_vocab.encode(i) for i in src_data]\n",
    "            trg_idx = [self.en_vocab.encode(i) for i in trg_data]\n",
    "\n",
    "            src_idx, trg_idx = sort_by_length(src_idx, trg_idx)\n",
    "            src_idx_pad, src_len = pad(src_idx, de_vocab, max_len)\n",
    "            trg_idx_pad, _ = pad(trg_idx, en_vocab, max_len)\n",
    "\n",
    "            return src_idx_pad, src_len, trg_idx_pad\n",
    "\n",
    "        for i in range(self.len):\n",
    "            if i == self.len - 1 and not self.drop_reminder:\n",
    "                batch_data = self.dataset[i * self.batch_size:]\n",
    "            else:\n",
    "                batch_data = self.dataset[i * self.batch_size: (i+1) * self.batch_size]\n",
    "\n",
    "            src_idx, src_len, trg_idx = encode_and_pad(batch_data, self.max_len)\n",
    "            yield mindspore.Tensor(src_idx, mindspore.int32), \\\n",
    "                mindspore.Tensor(src_len, mindspore.int32), \\\n",
    "                mindspore.Tensor(trg_idx, mindspore.int32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "train_iterator = Iterator(train_dataset, de_vocab, en_vocab, batch_size=128, max_len=32, drop_reminder=True)\n",
    "valid_iterator = Iterator(valid_dataset, de_vocab, en_vocab, batch_size=128, max_len=32, drop_reminder=False)\n",
    "test_iterator = Iterator(test_dataset, de_vocab, en_vocab, batch_size=1, max_len=32, drop_reminder=False)\n",
    "\n",
    "for src_idx, src_len, trg_idx in train_iterator():\n",
    "    print(f'src_idx.shape:{src_idx.shape}\\n{src_idx}\\nsrc_len.shape:{src_len.shape}\\n{src_len}\\ntrg_idx.shape:{trg_idx.shape}\\n{trg_idx}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e863eaa7",
   "metadata": {},
   "source": [
    "从上面的打印可以看出，每个batch有128个句子，每个句子的有效长度不尽相同，但总长度都被统一处理成了32。\n",
    "\n",
    "### word embedding\n",
    "\n",
    "词元token的索引`index`无法准确表示词的含义，为此我们引入词向量来表示词元。`word embedding`操作就是把词元的索引映射到词向量的过程。刚开始训练时，词向量是随机初始化的，训练后期才趋于准确，因此下面的代码在执行时的结果具有随机性。另外，不同的任务对词向量的维度要求也不一样，这里的维度可以简单理解为词性分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fbe8c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01554022  0.00285271 -0.00301846  0.01385568]\n",
      " [-0.00593589 -0.00814702  0.00477153 -0.01148507]\n",
      " [-0.01231559 -0.00142939  0.00183586  0.00480045]\n",
      " [-0.00746783 -0.01290462 -0.01337912 -0.00208899]\n",
      " [-0.00259946 -0.00301206  0.00569997  0.01771126]\n",
      " [ 0.01209698  0.01102743  0.00870621  0.02020831]\n",
      " [-0.01231559 -0.00142939  0.00183586  0.00480045]\n",
      " [-0.02378692  0.00136542  0.01566702 -0.00175273]\n",
      " [ 0.0082812  -0.0114319  -0.01249129 -0.00563227]\n",
      " [-0.00310827 -0.00408182  0.00309918  0.00963262]]\n"
     ]
    }
   ],
   "source": [
    "from mindspore import nn, Tensor\n",
    "\n",
    "word_index = Tensor([21, 28, 49, 12, 275, 119, 49, 23, 54, 32])\n",
    "src_emb = nn.Embedding(len(de_vocab), 4)\n",
    "enc_outputs = src_emb(word_index)\n",
    "print(enc_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be4adeb",
   "metadata": {},
   "source": [
    "### 位置编码（Positional Encoding）\n",
    "\n",
    "位置编码$PE$的形状与经过word embedding后的输出$X$相同，对于索引为[pos, 2i]的元素，以及索引为[pos, 2i+1]的元素，位置编码的计算如下：\n",
    "\n",
    "$$PE_{(pos,2i)} = \\sin\\Bigg(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\Bigg)$$\n",
    "\n",
    "$$PE_{(pos,2i+1)} = \\cos\\Bigg(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\Bigg)$$\n",
    "\n",
    "在下面的代码中，我们实现了位置编码，输入经过word embedding后的结果$X$，输出添加位置信息后的结果$X + PE$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d781a459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:24:24.755.235 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.          1.          0.          1.        ]\n",
      "  [ 0.84147096  0.5403023   0.00999983  0.99995   ]\n",
      "  [ 0.9092974  -0.4161468   0.01999866  0.9998    ]\n",
      "  [ 0.14112009 -0.98999447  0.0299955   0.99955004]\n",
      "  [-0.7568025  -0.6536437   0.03998933  0.9992001 ]\n",
      "  [-0.9589243   0.28366202  0.04997917  0.9987502 ]\n",
      "  [-0.27941567  0.96017027  0.059964    0.99820054]\n",
      "  [ 0.6569864   0.7539024   0.06994284  0.997551  ]\n",
      "  [ 0.98935825 -0.14549987  0.07991469  0.99680173]\n",
      "  [ 0.4121185  -0.9111306   0.08987855  0.9959527 ]]]\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "from mindspore import nn, ops, Tensor\n",
    "from mindspore import dtype as mstype\n",
    "from mindspore import numpy as mnp\n",
    "\n",
    "class PositionalEncoding(nn.Cell):\n",
    "    \"\"\"位置编码\"\"\"\n",
    "\n",
    "    def __init__(self, d_model, dropout_p=0.1, max_len=100):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(1 - dropout_p)\n",
    "\n",
    "        self.pe = ops.Zeros()((max_len, d_model), mstype.float32)\n",
    "\n",
    "        pos = mnp.arange(0, max_len, dtype=mstype.float32).view((-1, 1))\n",
    "        angle = ops.pow(10000.0, mnp.arange(0, d_model, 2, dtype=mstype.float32)/d_model)\n",
    "\n",
    "        self.pe[:, 0::2] = ops.sin(pos/angle)\n",
    "        self.pe[:, 1::2] = ops.cos(pos/angle)\n",
    "\n",
    "    def construct(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        pe = self.pe.expand_dims(0)\n",
    "        pe = ops.broadcast_to(pe, (batch_size, -1, -1))\n",
    "\n",
    "        x = x + pe[:, :x.shape[1], :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "x = ops.Zeros()((1, 10, 4), mstype.float32)\n",
    "pe = PositionalEncoding(4)\n",
    "print(pe(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69867562",
   "metadata": {},
   "source": [
    "## 模型结构\n",
    "\n",
    "### 注意力机制\n",
    "\n",
    "相同的一句话，不同的人听的时候侧重点也可能不同。在自然语言处理中，根据任务内容的不同，句子中需要重点关注的部分也会不同。为此，我们引入注意力机制来判断在执行某个任务时，词在句子中的重要性，并通过注意力分数来表示词的重要程度。分数越高，说明该词对完成该任务的重要性越大。\n",
    "在计算注意力分数时，我们主要参考三个因素：**query**、**key**和**value**。\n",
    "\n",
    "- `query`：任务内容\n",
    "- `key`：索引/标签（帮助定位到答案）\n",
    "- `value`：答案\n",
    "\n",
    "注意力分数的计算公式为：\n",
    "\n",
    "$$\\text{Attention Score}(Q, K)=\\frac{QK^T}{\\sqrt{d_{model}}}$$\n",
    "\n",
    "同时，为了避免`query`（$Q \\in R^{n\\times d_{model}}$）和`key`($K \\in R^{m\\times d_{model}}$)本身的“大小”影响到相似度的计算，我们需要在点乘后除以$\\sqrt{d_{model}}$。\n",
    "\n",
    "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_{model}}}\\right)V$$\n",
    "\n",
    "在如下代码中，我们实现了scaled dot-product attention的计算， 调用类后，返回的是加权后的value（output）以及注意力权重（attn）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d3f8b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:24:30.489.731 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 8, 32, 64) (128, 8, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "class ScaledDotProductAttention(nn.Cell):\n",
    "    def __init__(self, dropout_p=0.):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.dropout = nn.Dropout(1-dropout_p)\n",
    "        self.sqrt = ops.Sqrt()\n",
    "\n",
    "\n",
    "    def construct(self, query, key, value, attn_mask=None):\n",
    "        \"\"\"scaled dot product attention\"\"\"\n",
    "        embed_size = query.shape[-1]\n",
    "        scaling_factor = self.sqrt(Tensor(embed_size, mstype.float16))\n",
    "\n",
    "        attn = ops.matmul(query, key.swapaxes(-2, -1) / scaling_factor)\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            attn = attn.masked_fill(attn_mask, -1e9)\n",
    "        attn = self.softmax(attn)\n",
    "        attn = self.dropout(attn)\n",
    "        output = ops.matmul(attn, value)\n",
    "\n",
    "        return (output, attn)\n",
    "\n",
    "\n",
    "attention = ScaledDotProductAttention()\n",
    "q_s = k_s = v_s = ops.ones((128, 8, 32, 64), mindspore.float32)\n",
    "attn_mask = ops.ones((128, 8, 32, 32), mindspore.float32)\n",
    "attn_mask = mindspore.ops.gt(attn_mask, attn_mask)\n",
    "output, attn = attention(q_s, k_s, v_s, attn_mask)\n",
    "print(output.shape, attn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ef924",
   "metadata": {},
   "source": [
    "### 多头注意力（Multi-Head Attention）\n",
    "\n",
    "多头注意力是注意力机制的扩展，它可以使模型通过不同的方式关注输入序列的不同部分，从而提升模型的训练效果。\n",
    "\n",
    "不同于之前一次计算整体输入的注意力分数，多头注意力是多次计算，每次计算输入序列中某一部分的注意力分数，最后再将结果进行整合。\n",
    "\n",
    "多头注意力通过对输入的embedding乘以不同的权重参数$W^{Q}$、$W^{K}$和$W^{V}$，将其映射到多个小维度空间中，我们称之为“头”（head），每个头部会并行计算自己的自注意力分数。\n",
    "\n",
    "$$\\text{head}_i = \\text{Attention}(QW^Q_i, KW^K_i, VW^V_i) = \\text{softmax}\\left(\\frac{Q_iK_i^T}{\\sqrt{d_{k}}}\\right)V_i$$\n",
    "\n",
    "$W^Q_i \\in \\mathbb{R}^{d_{model}\\times d_{k}}$、$W^K_i \\in \\mathbb{R}^{d_{model}\\times d_{k}}$和$W^V_i \\in \\mathbb{R}^{d_{model}\\times d_{v}}$为可学习的权重参数。一般为了平衡计算成本，我们会取$d_k = d_v = d_{model} / n_{head}$。\n",
    "\n",
    "在获得多组自注意力分数后，我们将结果拼接到一起，得到多头注意力的最终输出。$W^O$为可学习的权重参数，用于将拼接后的多头注意力输出映射回原来的维度。\n",
    "\n",
    "$$\\text{MultiHead}(Q, K, V)=\\text{Concat}(\\text{head}_1, ..., \\text{head}_h)W^O$$\n",
    "\n",
    "简单来说，在多头注意力中，每个头部可以'解读'输入内容的不同方面，比如：捕捉全局依赖关系、关注特定语境下的词元、识别词和词之间的语法关系等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8a89cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:25:00.494.824 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output.shape:(128, 32, 512)\n",
      "attn_mask.shape:(128, 8, 32, 32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(nn.Cell):\n",
    "    def __init__(self, d_model, d_k, n_heads, dropout_p=0.):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_k\n",
    "        self.W_Q = nn.Dense(d_model, d_k * n_heads)\n",
    "        self.W_K = nn.Dense(d_model, d_k * n_heads)\n",
    "        self.W_V = nn.Dense(d_model, d_k * n_heads)\n",
    "        self.W_O = nn.Dense(n_heads * d_k, d_model)\n",
    "        self.attention = ScaledDotProductAttention(dropout_p=dropout_p)\n",
    "\n",
    "    def construct(self, query, key, value, attn_mask):\n",
    "        \"\"\"\n",
    "        query: [batch_size, len_q, d_model]\n",
    "        key: [batch_size, len_k, d_model]\n",
    "        value: [batch_size, len_k, d_model]\n",
    "        attn_mask: [batch_size, seq_len, seq_len]\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = query.shape[0]\n",
    "\n",
    "        q_s = self.W_Q(query).view(batch_size, -1, self.n_heads, self.d_k)\n",
    "        k_s = self.W_K(key).view(batch_size, -1, self.n_heads, self.d_k)\n",
    "        v_s = self.W_V(value).view(batch_size, -1, self.n_heads, self.d_k)\n",
    "\n",
    "        q_s = q_s.transpose((0, 2, 1, 3))\n",
    "        k_s = k_s.transpose((0, 2, 1, 3))\n",
    "        v_s = v_s.transpose((0, 2, 1, 3))\n",
    "\n",
    "        attn_mask = attn_mask.expand_dims(1)\n",
    "        attn_mask = ops.tile(attn_mask, (1, self.n_heads, 1, 1))\n",
    "\n",
    "        context, attn = self.attention(q_s, k_s, v_s, attn_mask)\n",
    "\n",
    "        context = context.transpose((0, 2, 1, 3)).view((batch_size, -1, self.n_heads * self.d_k))\n",
    "\n",
    "        output = self.W_O(context)\n",
    "\n",
    "        return output, attn\n",
    "\n",
    "enc_input = ops.ones((128, 32, 512), mindspore.float32)\n",
    "attn_mask = ops.ones((128, 32, 32), mindspore.float32)\n",
    "attn_mask = mindspore.ops.gt(attn_mask, attn_mask)\n",
    "\n",
    "mha = MultiHeadAttention(512, 64, 8)\n",
    "output, attn = mha(enc_input, enc_input, enc_input, attn_mask)\n",
    "print(\"output.shape:{}\\nattn_mask.shape:{}\\n\".format(output.shape, attn.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab926df",
   "metadata": {},
   "source": [
    "在上面介绍[数据迭代器](#数据迭代器)时有提到，不同的句子token个数也不尽相同，我们为了统一模型输入的长度，使用\\<pad\\>占位符补齐一些稍短的文本。\n",
    "\n",
    "```text\n",
    "处理前：\"Hello world!\"\n",
    "处理后：<bos> hello world ! <eos> <pad> <pad>\n",
    "```\n",
    "\n",
    "这些\\<pad\\>占位符没有任何意义，不应该参与注意力分数计算中。为此我们在注意力中加入了padding掩码，即识别输入序列中的\\<pad\\>占位符，保证计算时这些位置对应的注意力分数为0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ab19a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[False False  True  True]\n",
      "  [False False  True  True]\n",
      "  [False False  True  True]\n",
      "  [False False  True  True]]]\n"
     ]
    }
   ],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k, pad_idx):\n",
    "    \"\"\"注意力掩码：识别序列中的<pad>占位符\n",
    "\n",
    "    Args:\n",
    "        seq_q (Tensor): query序列，shape = [batch size, query len]\n",
    "        seq_k (Tensor): key序列，shape = [batch size, key len]\n",
    "        pad_idx (Tensor): key序列<pad>占位符对应的数字索引\n",
    "    \"\"\"\n",
    "    batch_size, len_q = seq_q.shape\n",
    "    batch_size, len_k = seq_k.shape\n",
    "\n",
    "    pad_attn_mask = ops.equal(seq_k, pad_idx)\n",
    "\n",
    "    pad_attn_mask = pad_attn_mask.expand_dims(1)\n",
    "    pad_attn_mask = ops.broadcast_to(pad_attn_mask, (batch_size, len_q, len_k))\n",
    "\n",
    "    return pad_attn_mask\n",
    "\n",
    "q = k = Tensor([[1, 1, 0, 0]], mstype.float32)\n",
    "pad_idx = 0\n",
    "mask = get_attn_pad_mask(q, k, pad_idx)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16e2b0a",
   "metadata": {},
   "source": [
    "### 基于位置的前馈神经网络 （Position-Wise Feed-Forward Network）\n",
    "\n",
    "基于位置的前馈神经网络被用来对输入中的每个位置进行非线性变换。它由两个线性层组成，层与层之间需要经过ReLU激活函数。\n",
    "\n",
    "$$\\mathrm{FFN}(x) = \\mathrm{ReLU}(xW_1 + b_1)W_2 + b_2$$\n",
    "\n",
    "相比固定的ReLU函数，基于位置的前馈神经网络可以处理更加复杂的关系，并且由于前馈网络是基于位置的，可以捕获到不同位置的信息，并为每个位置提供不同的转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "969ae745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:25:27.140.692 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32, 512)\n"
     ]
    }
   ],
   "source": [
    "class PoswiseFeedForward(nn.Cell):\n",
    "    def __init__(self, d_ff, d_model, dropout_p=0.):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Dense(d_model, d_ff)\n",
    "        self.linear2 = nn.Dense(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(1-dropout_p)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\"前馈神经网络\n",
    "        x: [batch_size, seq_len, d_model]\n",
    "        \"\"\"\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        output = self.linear2(x)\n",
    "        return output\n",
    "\n",
    "x = ops.ones((128, 32, 512), mstype.float32)\n",
    "ffn = PoswiseFeedForward(2048, 512)\n",
    "print(ffn(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbddb77",
   "metadata": {},
   "source": [
    "### Add & Norm\n",
    "\n",
    "Add & Norm层本质上是残差连接后紧接了一个LayerNorm层。\n",
    "\n",
    "$\\text{Add&Norm}(x) = \\text{LayerNorm}(x + \\text{Sublayer}(x))$\n",
    "\n",
    "- Add：残差连接，帮助缓解网络退化问题，注意需要满足$x$与$\\text{SubLayer}(x)的形状一致$；\n",
    "- Norm：Layer Norm，层归一化，帮助模型更快地进行收敛；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "810920e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNorm(nn.Cell):\n",
    "    def __init__(self, d_model, dropout_p=0.):\n",
    "        super().__init__()\n",
    "        self.layer_norm = nn.LayerNorm((d_model, ), epsilon=1e-5)\n",
    "        self.dropout = nn.Dropout(1-dropout_p)\n",
    "    \n",
    "    def construct(self, x, residual):\n",
    "        return self.layer_norm(self.dropout(x) + residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f931d3d8",
   "metadata": {},
   "source": [
    "### Encoder Layer\n",
    "\n",
    "我们首先实现encoder中的一个层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9fd6dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:25:35.106.230 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:25:35.125.701 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:25:35.130.539 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:25:35.134.378 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32, 512) (128, 8, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "class EncoderLayer(nn.Cell):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout_p=0.):\n",
    "        super().__init__()\n",
    "        d_k = d_model // n_heads\n",
    "        if d_k * n_heads != d_model:\n",
    "            raise ValueError(f\"The `d_model` {d_model} can not be divisible by `num_heads` {n_heads}.\")\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, d_k, n_heads, dropout_p)\n",
    "        self.pos_ffn = PoswiseFeedForward(d_ff, d_model, dropout_p)\n",
    "        self.add_norm1 = AddNorm(d_model, dropout_p)\n",
    "        self.add_norm2 = AddNorm(d_model, dropout_p)\n",
    "        \n",
    "    def construct(self, enc_inputs, enc_self_attn_mask):\n",
    "        \"\"\"\n",
    "        enc_inputs: [batch_size, src_len, d_model]\n",
    "        enc_self_attn_mask: [batch_size, src_len, src_len]\n",
    "        \"\"\"\n",
    "        residual = enc_inputs\n",
    "\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask)\n",
    "\n",
    "        enc_outputs = self.add_norm1(enc_outputs, residual)\n",
    "        residual = enc_outputs\n",
    "\n",
    "        enc_outputs = self.pos_ffn(enc_outputs)\n",
    "\n",
    "        enc_outputs = self.add_norm2(enc_outputs, residual)\n",
    "\n",
    "        return enc_outputs, attn\n",
    "\n",
    "x = ops.ones((128, 32, 512), mstype.float32)\n",
    "mask = Tensor([False]).broadcast_to((128, 32, 32))\n",
    "encoder_layer = EncoderLayer(512, 8, 2018)\n",
    "output, attn = encoder_layer(x, mask)\n",
    "print(output.shape, attn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c8c84a",
   "metadata": {},
   "source": [
    "###  编码器 Encoder\n",
    "\n",
    "将上面实现的encoder层堆叠`n_layers`次，并添加wording embedding与positional encoding。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "482f5570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:25:47.206.827 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:25:47.248.429 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:25:47.273.994 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:25:47.278.824 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:25:47.282.744 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_outputs.shape:(128, 32, 512)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Cell):\n",
    "    def __init__(self, src_vocab_size, d_model, n_heads, d_ff, n_layers, dropout_p=0.):\n",
    "        super().__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.pos_emb = PositionalEncoding(d_model, dropout_p)\n",
    "        self.layers = nn.CellList([EncoderLayer(d_model, n_heads, d_ff, dropout_p)] * n_layers)\n",
    "        self.scaling_factor = ops.Sqrt()(Tensor(d_model, mstype.float32))\n",
    "\n",
    "    def construct(self, enc_inputs, src_pad_idx):\n",
    "        \"\"\"enc_inputs : [batch_size, src_len]\n",
    "        \"\"\"\n",
    "        enc_outputs = self.src_emb(enc_inputs.astype(mstype.int32))\n",
    "        enc_outputs = self.pos_emb(enc_outputs * self.scaling_factor)\n",
    "\n",
    "        enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs, src_pad_idx)\n",
    "\n",
    "        enc_self_attns = []\n",
    "        for layer in self.layers:\n",
    "            enc_outputs, enc_self_attn = layer(enc_outputs, enc_self_attn_mask)\n",
    "            enc_self_attns.append(enc_self_attn)\n",
    "        return enc_outputs, enc_self_attns\n",
    "\n",
    "encoder = Encoder(len(de_vocab), 512, 8, 2048, 6)\n",
    "\n",
    "for src_idx, src_len, trg_idx in train_iterator():\n",
    "    enc_outputs, enc_self_attns = encoder(src_idx, de_vocab.pad_idx)\n",
    "    print(\"enc_outputs.shape:{}\\n\".format(enc_outputs.shape))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a951928a",
   "metadata": {},
   "source": [
    "解码器将编码器输出的上下文序列转换为目标序列的预测结果$\\hat{Y}$，该输出将在模型训练中与真实目标输出$Y$进行比较，计算损失。\n",
    "\n",
    "不同于编码器，每个Decoder层中包含两层多头注意力机制,并在最后多出一个线性层，输出对目标序列的预测结果。\n",
    "\n",
    "- 第一层：计算目标序列的注意力分数的**掩码多头自注意力**；\n",
    "- 第二层：用于计算上下文序列与目标序列对应关系，其中Decoder掩码多头注意力的输出作为query，Encoder的输出（上下文序列）作为key和value；\n",
    "\n",
    "#### 带掩码的多头注意力\n",
    "\n",
    "在处理目标序列的输入时，t时刻的模型只能“观察”直到t-1时刻的所有词元，后续的词语不应该一并输入Decoder中。\n",
    "\n",
    "为了保证在t时刻，只有t-1个词元作为输入参与多头注意力分数的计算，我们需要在第一个多头注意力中额外增加一个时间掩码，使目标序列中的词随时间发展逐个被暴露出来。\n",
    "\n",
    "该注意力掩码可通过三角矩阵实现，对角线以上的词元表示为不参与注意力计算的词元，标记为1。\n",
    "\n",
    "$$\\begin{matrix}\n",
    "0 & 1 & 1 & 1 & 1\\\\\n",
    "0 & 0 & 1 & 1 & 1\\\\\n",
    "0 & 0 & 0 & 1 & 1\\\\\n",
    "0 & 0 & 0 & 0 & 1\\\\\n",
    "0 & 0 & 0 & 0 & 0\\\\\n",
    "\\end{matrix}$$\n",
    "\n",
    "该掩码一般被称作subsequent mask。\n",
    "\n",
    "最后，将subsequent mask和padding mask合并为一个整体的掩码，确保模型既不会注意到t时刻以后的词元，也不会关注为\\<pad\\>的词元。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dc0140e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 1. 1. 1.]\n",
      "  [0. 0. 1. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "def get_attn_subsequent_mask(seq_q, seq_k):\n",
    "    \"\"\"生成时间掩码，使decoder在第t时刻只能看到序列的前t-1个元素\n",
    "    \n",
    "    Args:\n",
    "        seq_q (Tensor): query序列，shape = [batch size, len_q]\n",
    "        seq_k (Tensor): key序列，shape = [batch size, len_k]\n",
    "    \"\"\"\n",
    "    batch_size, len_q = seq_q.shape\n",
    "    batch_size, len_k = seq_k.shape\n",
    "    ones = ops.ones((batch_size, len_q, len_k), mindspore.float32)\n",
    "    subsequent_mask = mnp.triu(ones, k=1)\n",
    "    return subsequent_mask\n",
    "\n",
    "q = k = ops.ones((1, 4), mstype.float32)\n",
    "mask = get_attn_subsequent_mask(q, k)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e3881b",
   "metadata": {},
   "source": [
    "### Decoder Layer\n",
    "\n",
    "首先实现Decoder中的一个层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e10d368b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:25:56.434.840 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:25:56.452.774 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:25:56.470.341 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:25:56.474.682 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:25:56.478.513 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:25:56.482.862 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32, 512) (128, 8, 32, 32) (128, 8, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "class DecoderLayer(nn.Cell):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout_p=0.):\n",
    "        super().__init__()\n",
    "        d_k = d_model // n_heads\n",
    "        if d_k * n_heads != d_model:\n",
    "            raise ValueError(f\"The `d_model` {d_model} can not be divisible by `num_heads` {n_heads}.\")\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, d_k, n_heads, dropout_p)\n",
    "        self.dec_enc_attn = MultiHeadAttention(d_model, d_k, n_heads, dropout_p)\n",
    "        self.pos_ffn = PoswiseFeedForward(d_ff, d_model, dropout_p)\n",
    "        self.add_norm1 = AddNorm(d_model, dropout_p)\n",
    "        self.add_norm2 = AddNorm(d_model, dropout_p)\n",
    "        self.add_norm3 = AddNorm(d_model, dropout_p)\n",
    "        \n",
    "    def construct(self, dec_inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask):\n",
    "        \"\"\"\n",
    "        dec_inputs: [batch_size, trg_len, d_model]\n",
    "        enc_outputs: [batch_size, src_len, d_model]\n",
    "        dec_self_attn_mask: [batch_size, trg_len, trg_len]\n",
    "        dec_enc_attn_mask: [batch_size, trg_len, src_len]\n",
    "        \"\"\"\n",
    "        residual = dec_inputs\n",
    "        dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask)\n",
    "        dec_outputs = self.add_norm1(dec_outputs, residual)\n",
    "        residual = dec_outputs    \n",
    "        dec_outputs, dec_enc_attn = self.dec_enc_attn(dec_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\n",
    "        dec_outputs = self.add_norm2(dec_outputs, residual)\n",
    "        residual = dec_outputs\n",
    "        dec_outputs = self.pos_ffn(dec_outputs)\n",
    "        dec_outputs = self.add_norm3(dec_outputs, residual)\n",
    "\n",
    "        return dec_outputs, dec_self_attn, dec_enc_attn\n",
    "\n",
    "x = y = ops.ones((128, 32, 512), mstype.float32)\n",
    "mask1 = mask2 = Tensor([False]).broadcast_to((128, 32, 32))\n",
    "decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "output, attn1, attn2 = decoder_layer(x, y, mask1, mask2)\n",
    "print(output.shape, attn1.shape, attn2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0f682c",
   "metadata": {},
   "source": [
    "### 解码器 Decoder\n",
    "\n",
    "将上面实现的DecoderLayer堆叠`n_layer`次，添加word embedding与positional encoding，以及最后的线性层。\n",
    "\n",
    "输出的`dec_outputs`为对目标序列的预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db7f8360",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Cell):\n",
    "    def __init__(self, trg_vocab_size, d_model, n_heads, d_ff, n_layers, dropout_p=0.):\n",
    "        super().__init__()\n",
    "        self.trg_emb = nn.Embedding(trg_vocab_size, d_model)\n",
    "        self.pos_emb = PositionalEncoding(d_model, dropout_p)\n",
    "        self.layers = nn.CellList([DecoderLayer(d_model, n_heads, d_ff) for _ in range(n_layers)])\n",
    "        self.projection = nn.Dense(d_model, trg_vocab_size)\n",
    "        self.scaling_factor = ops.Sqrt()(Tensor(d_model, mstype.float32))      \n",
    "        \n",
    "    def construct(self, dec_inputs, enc_inputs, enc_outputs, src_pad_idx, trg_pad_idx):\n",
    "        \"\"\"\n",
    "        dec_inputs: [batch_size, trg_len]\n",
    "        enc_inputs: [batch_size, src_len]\n",
    "        enc_outputs: [batch_size, src_len, d_model]\n",
    "        \"\"\"\n",
    "        dec_outputs = self.trg_emb(dec_inputs.astype(mstype.int32))\n",
    "        dec_outputs = self.pos_emb(dec_outputs * self.scaling_factor)\n",
    "\n",
    "        dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, trg_pad_idx)\n",
    "        dec_self_attn_subsequent_mask = get_attn_subsequent_mask(dec_inputs, dec_inputs)\n",
    "        dec_self_attn_mask = ops.gt((dec_self_attn_pad_mask + dec_self_attn_subsequent_mask), 0)\n",
    "\n",
    "        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs, src_pad_idx)\n",
    "\n",
    "        dec_self_attns, dec_enc_attns = [], []\n",
    "        for layer in self.layers:\n",
    "            dec_outputs, dec_self_attn, dec_enc_attn = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n",
    "            dec_self_attns.append(dec_self_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        dec_outputs = self.projection(dec_outputs)\n",
    "        return dec_outputs, dec_self_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24dec57",
   "metadata": {},
   "source": [
    "### Transformer\n",
    "\n",
    "将实现的Encoder与Decoder组合起来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "599d3b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Cell):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.encoder.to_float(mindspore.float16)\n",
    "        self.decoder.to_float(mindspore.float16)\n",
    "        \n",
    "    def construct(self, enc_inputs, dec_inputs, src_pad_idx, trg_pad_idx):\n",
    "        \"\"\"\n",
    "        enc_inputs: [batch_size, src_len]\n",
    "        dec_inputs: [batch_size, trg_len]\n",
    "        \"\"\"\n",
    "        enc_outputs, enc_self_attns = self.encoder(enc_inputs, src_pad_idx)\n",
    "\n",
    "        dec_outputs, dec_self_attns, dec_enc_attns = self.decoder(dec_inputs, enc_inputs, enc_outputs, src_pad_idx, trg_pad_idx)\n",
    "\n",
    "        dec_logits = dec_outputs.view((-1, dec_outputs.shape[-1]))\n",
    "\n",
    "        return dec_logits, enc_self_attns, dec_self_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f78073",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "定义超参数，实例化Transformer模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59c9ba5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:03.925.399 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:03.958.554 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:03.979.098 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:03.983.927 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:03.987.770 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.112.40 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.334.39 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.583.01 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.758.22 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.802.75 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.843.73 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.887.34 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.116.250 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.135.314 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.152.654 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.157.203 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.161.050 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.165.581 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.184.598 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.219.729 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.238.129 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.242.704 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.246.525 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.250.828 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.272.219 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.311.862 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.330.861 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.335.258 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.339.142 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.343.473 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.362.887 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.382.071 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.414.216 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.419.019 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.422.916 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.427.334 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.449.132 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.468.060 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.484.545 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.488.914 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.492.795 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:26:04.497.136 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(de_vocab)\n",
    "trg_vocab_size = len(en_vocab)\n",
    "src_pad_idx = de_vocab.pad_idx\n",
    "trg_pad_idx = en_vocab.pad_idx\n",
    "\n",
    "d_model = 512\n",
    "d_ff = 2048\n",
    "n_layers = 6\n",
    "n_heads = 8\n",
    "\n",
    "encoder = Encoder(src_vocab_size, d_model, n_heads, d_ff, n_layers, dropout_p=0.1)\n",
    "decoder = Decoder(trg_vocab_size, d_model, n_heads, d_ff, n_layers, dropout_p=0.1)\n",
    "model = Transformer(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee15980",
   "metadata": {},
   "source": [
    "定义损失函数与优化器。\n",
    "\n",
    "- 损失函数：定义如何计算模型输出(logits)与目标(targets)之间的误差，这里可以使用交叉熵损失（CrossEntropyLoss）\n",
    "- 优化器：MindSpore将模型优化算法的实现称为**优化器**。优化器内部定义了模型的参数优化过程（即梯度如何更新至模型参数），所有优化逻辑都封装在优化器对象中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cbc316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(ignore_index=trg_pad_idx)\n",
    "optimizer = nn.Adam(model.trainable_params(), learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78377af4",
   "metadata": {},
   "source": [
    "### 模型训练逻辑\n",
    "\n",
    "1. Network+loss function直接构造正向函数\n",
    "2. 函数变换，获得梯度计算（反向传播）函数\n",
    "3. 构造训练过程函数\n",
    "4. 调用函数进行训练\n",
    "\n",
    "定义前向网络计算逻辑。\n",
    "\n",
    "在训练过程中，表示句子结尾的\\<eos\\>占位符应是被模型预测出来，而不是作为模型的输入，所以在处理Decoder的输入时，我们需要移除目标序列最末的\\<eos\\>占位符。\n",
    "\n",
    "$$\\text{trg} = [\\text{<bos>}, x_1, x_2, ..., x_n, \\text{<eos>}]$$\n",
    "$$\\text{trg[:-1]} = [\\text{<bos>}, x_1, x_2, ..., x_n]$$\n",
    "\n",
    "其中，$x_i$代表目标序列中第i个表示实际内容的词元。\n",
    "\n",
    "我们期望最终的输出包含表示句末的\\<eos\\>，不包含表示句首的\\<bos\\>，所以在计算损失时，需要同样去除的目标序列的句首\\<bos\\>占位符，再进行比较。\n",
    "\n",
    "$$\\text{output} = [y_1, y_2, ..., y_n, \\text{<eos>}]$$\n",
    "$$\\text{trg[1:]} = [x_1, x_2, ..., x_n, \\text{<bos>}]$$\n",
    "\n",
    "其中，$y_i$表示预测的第i个实际内容词元。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c96e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(enc_inputs, dec_inputs):\n",
    "    \"\"\"前向网络\n",
    "    enc_inputs: [batch_size, src_len]\n",
    "    dec_inputs: [batch_size, trg_len]\n",
    "    \"\"\"\n",
    "    logits, _, _, _ = model(enc_inputs, dec_inputs[:, :-1], src_pad_idx, trg_pad_idx)\n",
    "\n",
    "    targets = dec_inputs[:, 1:].view(-1)\n",
    "    loss = loss_fn(logits, targets)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463c2ba8",
   "metadata": {},
   "source": [
    "定义梯度计算函数。\n",
    "\n",
    "为了优化模型参数，需要求参数对loss的导数。我们调用`mindspore.ops.value_and_grad`函数，来获得function的微分函数。\n",
    "\n",
    "常用到的参数有三种：\n",
    "\n",
    "- fn：待求导的函数；\n",
    "- grad_position：指定求导输入位置的索引；\n",
    "- weights：指定求导的参数；\n",
    "\n",
    "由于使用Cell封装神经网络模型，模型参数为Cell的内部属性，此时我们不需要使用`grad_position`指定对函数输入求导，因此将其配置为None。对模型参数求导时，我们使用weights参数，使用`model.trainable_params()`方法从Cell中取出可以求导的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb96a444",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_fn = ops.value_and_grad(forward, None, optimizer.parameters)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(iterator, epoch=0):\n",
    "    model.set_train(True)\n",
    "    num_batches = len(iterator)\n",
    "    total_loss = 0\n",
    "    total_steps = 0\n",
    "\n",
    "    with tqdm(total=num_batches, unit='step', desc='Train   ') as t:\n",
    "        for src, src_len, trg in iterator():\n",
    "            loss, grads = grad_fn(src, trg)\n",
    "            optimizer(grads)\n",
    "\n",
    "            total_loss += loss.asnumpy()\n",
    "            total_steps += 1\n",
    "            curr_loss = total_loss / total_steps\n",
    "            t.set_postfix({'loss': f'{curr_loss:.2f}', 'epoch': f'{epoch:03}'})\n",
    "            t.update(1)\n",
    "\n",
    "    return total_loss / total_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c9e3e4",
   "metadata": {},
   "source": [
    "定义模型评估逻辑。\n",
    "\n",
    "在评估中，仅需正向计算loss，无需更新模型参数,故模型状态需设置为训练`model.set_train(False)`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20baec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(iterator):\n",
    "    model.set_train(False)\n",
    "    num_batches = len(iterator)\n",
    "    total_loss = 0\n",
    "    total_steps = 0\n",
    "\n",
    "    with tqdm(total=num_batches, unit='step', desc='Evaluate') as t:\n",
    "        for src, _, trg in iterator():\n",
    "            loss = forward(src, trg)\n",
    "            total_loss += loss.asnumpy()\n",
    "            total_steps += 1\n",
    "            curr_loss = total_loss / total_steps\n",
    "            t.set_postfix({'loss': f'{curr_loss:.2f}'})\n",
    "            t.update(1)\n",
    "\n",
    "    return total_loss / total_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e360ace1",
   "metadata": {},
   "source": [
    "数据集遍历迭代，一次完整的数据集遍历成为一个epoch。我们逐个epoch打印训练的损失值和评估精度，并通过`save_checkpoint`保存评估精度最高的ckpt文件（transformer.ckpt）到home_path/.mindspore_examples/transformer.ckpt。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b91dc84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train   :   0%|          | 0/226 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train   : 100%|██████████| 226/226 [02:03<00:00,  1.83step/s, loss=4.50, epoch=000]\n",
      "Evaluate:  88%|████████▊ | 7/8 [00:00<00:00,  7.57step/s, loss=3.40]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate: 100%|██████████| 8/8 [00:03<00:00,  2.21step/s, loss=3.43]\n",
      "Train   : 100%|██████████| 226/226 [01:03<00:00,  3.57step/s, loss=3.05, epoch=001]\n",
      "Evaluate: 100%|██████████| 8/8 [00:01<00:00,  7.73step/s, loss=2.55]\n",
      "Train   : 100%|██████████| 226/226 [01:04<00:00,  3.51step/s, loss=2.40, epoch=002]\n",
      "Evaluate: 100%|██████████| 8/8 [00:01<00:00,  7.48step/s, loss=2.15]\n",
      "Train   : 100%|██████████| 226/226 [01:05<00:00,  3.45step/s, loss=2.02, epoch=003]\n",
      "Evaluate: 100%|██████████| 8/8 [00:01<00:00,  6.92step/s, loss=1.94]\n",
      "Train   : 100%|██████████| 226/226 [01:04<00:00,  3.50step/s, loss=1.76, epoch=004]\n",
      "Evaluate: 100%|██████████| 8/8 [00:01<00:00,  7.67step/s, loss=1.80]\n",
      "Train   : 100%|██████████| 226/226 [01:04<00:00,  3.50step/s, loss=1.56, epoch=005]\n",
      "Evaluate: 100%|██████████| 8/8 [00:01<00:00,  7.15step/s, loss=1.72]\n",
      "Train   : 100%|██████████| 226/226 [01:03<00:00,  3.54step/s, loss=1.39, epoch=006]\n",
      "Evaluate: 100%|██████████| 8/8 [00:01<00:00,  7.64step/s, loss=1.67]\n",
      "Train   : 100%|██████████| 226/226 [01:04<00:00,  3.49step/s, loss=1.25, epoch=007]\n",
      "Evaluate: 100%|██████████| 8/8 [00:01<00:00,  7.33step/s, loss=1.63]\n",
      "Train   : 100%|██████████| 226/226 [01:04<00:00,  3.52step/s, loss=1.13, epoch=008]\n",
      "Evaluate: 100%|██████████| 8/8 [00:01<00:00,  7.38step/s, loss=1.61]\n",
      "Train   : 100%|██████████| 226/226 [01:05<00:00,  3.48step/s, loss=1.02, epoch=009]\n",
      "Evaluate: 100%|██████████| 8/8 [00:01<00:00,  7.72step/s, loss=1.60]\n"
     ]
    }
   ],
   "source": [
    "from mindspore import save_checkpoint\n",
    "\n",
    "num_epochs = 10\n",
    "best_valid_loss = float('inf')\n",
    "ckpt_file_name = './transformer.ckpt'\n",
    "\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    train_loss = train(train_iterator, i)\n",
    "    valid_loss = evaluate(valid_iterator)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        save_checkpoint(model, ckpt_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf4d323",
   "metadata": {},
   "source": [
    "## 模型推理\n",
    "\n",
    "首先，通过`load_checkpoint`与`load_param_into_net`将训练好的模型参数加载入新实例化的模型中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8df0d97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.607.459 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.631.773 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.649.719 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.654.578 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.658.372 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.679.742 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.709.647 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.729.406 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.747.447 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.751.871 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.755.596 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.759.272 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.778.911 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.820.760 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.838.398 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.842.800 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.846.535 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.850.249 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.870.513 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.913.281 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.931.698 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.936.210 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.939.944 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.944.440 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.964.147 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:39:59.985.918 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:40:00.185.76 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:40:00.229.08 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:40:00.266.56 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:40:00.305.23 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:40:00.514.52 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:40:00.701.74 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:40:00.954.32 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:40:00.999.75 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:40:00.104.006 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:40:00.107.813 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:40:00.128.372 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:40:00.149.135 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:40:00.166.137 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:40:00.171.200 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:40:00.175.177 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2477:281473390059696,MainProcess):2024-04-12-15:40:00.179.720 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "\n",
    "encoder = Encoder(src_vocab_size, d_model, n_heads, d_ff, n_layers, dropout_p=0.1)\n",
    "decoder = Decoder(trg_vocab_size, d_model, n_heads, d_ff, n_layers, dropout_p=0.1)\n",
    "new_model = Transformer(encoder, decoder)\n",
    "\n",
    "param_dict = load_checkpoint(ckpt_file_name)\n",
    "load_param_into_net(new_model, param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0812263",
   "metadata": {},
   "source": [
    "推理过程中无需对模型参数进行更新，所以这里`model.set_train(False)`。\n",
    "\n",
    "我们输入一个德文语句，期望可以返回翻译好的英文语句。\n",
    "\n",
    "首先通过Encoder提取德文序列中的特征信息，并将其传输至Decoder。Decoder最开始的输入为起始占位符\\<bos\\>，每次会根据输入预测下一个出现的单词，并对输入进行更新，直到预测出终止占位符\\<eos\\>。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d5eeb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(sentence, max_len=32):\n",
    "    \"\"\"模型推理：输入一个德语句子，输出翻译后的英文句子\n",
    "    enc_inputs: [batch_size(1), src_len]\n",
    "    \"\"\"\n",
    "    new_model.set_train(False)\n",
    "\n",
    "    if isinstance(sentence, str):\n",
    "        tokens = [tok.lower() for tok in re.findall(r'\\w+|[^\\w\\s]', sentence.rstrip())]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    if len(tokens) > max_len - 2:\n",
    "        src_len = max_len\n",
    "        tokens = ['<bos>'] + tokens[:max_len - 2] + ['<eos>']\n",
    "    else:\n",
    "        src_len = len(tokens) + 2\n",
    "        tokens = ['<bos>'] + tokens + ['<eos>'] + ['<pad>'] * (max_len - src_len)\n",
    "\n",
    "    indexes = de_vocab.encode(tokens)\n",
    "    enc_inputs = Tensor(indexes, mstype.float32).expand_dims(0)\n",
    "\n",
    "    enc_outputs, _ = new_model.encoder(enc_inputs, src_pad_idx)\n",
    "\n",
    "    dec_inputs = Tensor([[en_vocab.bos_idx]], mstype.float32)\n",
    "\n",
    "    max_len = enc_inputs.shape[1]\n",
    "    for _ in range(max_len):\n",
    "        dec_outputs, _, _ = new_model.decoder(dec_inputs, enc_inputs, enc_outputs, src_pad_idx, trg_pad_idx)\n",
    "        dec_logits = dec_outputs.view((-1, dec_outputs.shape[-1]))\n",
    "\n",
    "        dec_logits = dec_logits[-1, :]\n",
    "        pred = dec_logits.argmax(axis=0).expand_dims(0).expand_dims(0)\n",
    "        pred = pred.astype(mstype.float32)\n",
    "\n",
    "        dec_inputs = ops.concat((dec_inputs, pred), axis=1)\n",
    "\n",
    "        if int(pred.asnumpy()[0]) == en_vocab.eos_idx:\n",
    "            break\n",
    "\n",
    "    trg_indexes = [int(i) for i in dec_inputs.view(-1).asnumpy()]\n",
    "    eos_idx = trg_indexes.index(en_vocab.eos_idx) if en_vocab.eos_idx in trg_indexes else -1\n",
    "    trg_tokens = en_vocab.decode(trg_indexes[1:eos_idx])\n",
    "\n",
    "    return trg_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d8c19d",
   "metadata": {},
   "source": [
    "以测试数据集中的第一组语句为例，进行测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94df1275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = ['ein', 'mann', 'mit', 'einem', 'orangefarbenen', 'hut', ',', 'der', 'etwas', 'anstarrt', '.']\n",
      "trg = ['a', 'man', 'in', 'an', 'orange', 'hat', 'starring', 'at', 'something', '.']\n",
      "predicted trg = ['a', 'man', 'in', 'an', 'orange', 'hat', '<unk>', 'something', '.']\n"
     ]
    }
   ],
   "source": [
    "example_idx = 0\n",
    "\n",
    "src = test_dataset[example_idx][0]\n",
    "trg = test_dataset[example_idx][1]\n",
    "pred_trg = inference(src)\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')\n",
    "print(f\"predicted trg = {pred_trg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03605d67",
   "metadata": {},
   "source": [
    "## BLEU得分\n",
    "\n",
    "双语替换评测得分（bilingual evaluation understudy，BLEU）为衡量文本翻译模型生成出来的语句好坏的一种算法，它的核心在于评估机器翻译的译文 $\\text{pred}$ 与人工翻译的参考译文 $\\text{label}$ 的相似度。通过对机器译文的片段与参考译文进行比较，计算出各个片段的的分数，并配以权重进行加和，基本规则为：\n",
    "\n",
    "1. 惩罚过短的预测，即如果机器翻译出来的译文相对于人工翻译的参考译文过于短小，则命中率越高，需要施加更多的惩罚；\n",
    "2. 对长段落匹配更高的权重，即如果出现长段落的完全命中，说明机器翻译的译文更贴近人工翻译的参考译文；\n",
    "\n",
    "BLEU的公式如下：\n",
    "\n",
    "$$exp(min(0, 1-\\frac{len(\\text{label})}{len(\\text{pred})})\\Pi^k_{n=1}p_n^{1/2^n})$$\n",
    "\n",
    "- `len(label)`：人工翻译的译文长度\n",
    "- `len(pred)`：机器翻译的译文长度\n",
    "- `p_n`：n-gram的精度\n",
    "\n",
    "我们可以调用`nltk`中的`corpus_bleu`函数来计算BLEU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c85795fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score = 44.58\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def calculate_bleu(dataset, max_len=50):\n",
    "    trgs = []\n",
    "    pred_trgs = []\n",
    "    \n",
    "    for data in dataset[:10]:\n",
    "        \n",
    "        src = data[0]\n",
    "        trg = data[1]\n",
    "\n",
    "        pred_trg = inference(src, max_len)\n",
    "        pred_trgs.append(pred_trg)\n",
    "        trgs.append([trg])\n",
    "        \n",
    "    return corpus_bleu(trgs, pred_trgs)\n",
    "\n",
    "bleu_score = calculate_bleu(test_dataset)\n",
    "\n",
    "print(f'BLEU score = {bleu_score*100:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
