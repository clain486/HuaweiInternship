{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于MindSpore的GPT2文本摘要\n",
    "\n",
    "## 环境配置\n",
    "\n",
    "1. 安装tokenizers，版本为0.15.0；\n",
    "\n",
    "2. 需要手动安装mindspore2.2.13，npu版本，python环境为3.9，安装指南详见：[MindSpore安装](https://www.mindspore.cn/install)\n",
    "\n",
    "3. 安装MindNLP及相关依赖，MindNLP官方仓详见：[MindNLP](https://github.com/mindspore-lab/mindnlp)\n",
    "\n",
    "4. 安装pytest，版本要大于7.2；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Processing ./mindspore-2.2.13-cp39-cp39-linux_aarch64.whl\n",
      "Requirement already satisfied: astunparse>=1.6.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.2.13) (1.6.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.2.13) (1.22.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.2.13) (10.0.1)\n",
      "Requirement already satisfied: asttokens>=2.0.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.2.13) (2.4.1)\n",
      "Requirement already satisfied: scipy>=1.5.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.2.13) (1.10.1)\n",
      "Requirement already satisfied: protobuf>=3.13.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.2.13) (3.20.2)\n",
      "Requirement already satisfied: psutil>=5.6.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.2.13) (5.9.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.2.13) (23.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from asttokens>=2.0.4->mindspore==2.2.13) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from astunparse>=1.6.3->mindspore==2.2.13) (0.38.4)\n",
      "Installing collected packages: mindspore\n",
      "  Attempting uninstall: mindspore\n",
      "    Found existing installation: mindspore 2.2.0\n",
      "    Uninstalling mindspore-2.2.0:\n",
      "      Successfully uninstalled mindspore-2.2.0\n",
      "Successfully installed mindspore-2.2.13\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/MindSpore/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mindspore-2.2.13-cp39-cp39-linux_aarch64.whl -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://pip.modelarts.private.com:8888/repository/pypi/simple\n",
      "Processing ./mindnlp-0.2.0.20240229-py3-none-any.whl\n",
      "Requirement already satisfied: tqdm in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.2.0.20240229) (4.66.1)\n",
      "Requirement already satisfied: requests in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.2.0.20240229) (2.27.1)\n",
      "Requirement already satisfied: sentencepiece in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.2.0.20240229) (0.1.99)\n",
      "Collecting datasets\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/datasets/2.18.0/datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "\u001b[K     |████████████████████████████████| 510 kB 51.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/tokenizers/0.15.2/tokenizers-0.15.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 45.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: mindspore in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.2.0.20240229) (2.2.13)\n",
      "Collecting safetensors\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/safetensors/0.4.2/safetensors-0.4.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 62.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: easydict in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.2.0.20240229) (1.9)\n",
      "Collecting ml-dtypes\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/ml-dtypes/0.4.0/ml_dtypes-0.4.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 62.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.2.0.20240229) (2023.12.25)\n",
      "Collecting pyarrow-hotfix\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/pyarrow-hotfix/0.6/pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp==0.2.0.20240229) (0.20.1)\n",
      "Requirement already satisfied: filelock in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp==0.2.0.20240229) (3.13.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp==0.2.0.20240229) (0.3.7)\n",
      "Collecting xxhash\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/xxhash/3.4.1/xxhash-3.4.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (220 kB)\n",
      "\u001b[K     |████████████████████████████████| 220 kB 60.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp==0.2.0.20240229) (23.2)\n",
      "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp==0.2.0.20240229) (2023.12.2)\n",
      "Collecting aiohttp\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/aiohttp/3.9.3/aiohttp-3.9.3-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 58.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp==0.2.0.20240229) (1.3.5)\n",
      "Collecting multiprocess\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/multiprocess/0.70.16/multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 70.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp==0.2.0.20240229) (6.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp==0.2.0.20240229) (1.22.0)\n",
      "Collecting pyarrow>=12.0.0\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/pyarrow/15.0.2/pyarrow-15.0.2-cp39-cp39-manylinux_2_28_aarch64.whl (35.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 35.7 MB 59.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/yarl/1.9.4/yarl-1.9.4-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (300 kB)\n",
      "\u001b[K     |████████████████████████████████| 300 kB 64.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/aiosignal/1.3.1/aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/async-timeout/4.0.3/async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/multidict/6.0.5/multidict-6.0.5-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (125 kB)\n",
      "\u001b[K     |████████████████████████████████| 125 kB 43.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from aiohttp->datasets->mindnlp==0.2.0.20240229) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/frozenlist/1.4.1/frozenlist-1.4.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (239 kB)\n",
      "\u001b[K     |████████████████████████████████| 239 kB 65.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from huggingface-hub>=0.19.4->datasets->mindnlp==0.2.0.20240229) (4.9.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->mindnlp==0.2.0.20240229) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->mindnlp==0.2.0.20240229) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->mindnlp==0.2.0.20240229) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->mindnlp==0.2.0.20240229) (2.10)\n",
      "Requirement already satisfied: protobuf>=3.13.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore->mindnlp==0.2.0.20240229) (3.20.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore->mindnlp==0.2.0.20240229) (10.0.1)\n",
      "Requirement already satisfied: astunparse>=1.6.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore->mindnlp==0.2.0.20240229) (1.6.3)\n",
      "Requirement already satisfied: scipy>=1.5.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore->mindnlp==0.2.0.20240229) (1.10.1)\n",
      "Requirement already satisfied: asttokens>=2.0.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore->mindnlp==0.2.0.20240229) (2.4.1)\n",
      "Requirement already satisfied: psutil>=5.6.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore->mindnlp==0.2.0.20240229) (5.9.5)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from asttokens>=2.0.4->mindspore->mindnlp==0.2.0.20240229) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from astunparse>=1.6.3->mindspore->mindnlp==0.2.0.20240229) (0.38.4)\n",
      "Collecting dill<0.3.9,>=0.3.0\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/dill/0.3.8/dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[K     |████████████████████████████████| 116 kB 64.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pandas->datasets->mindnlp==0.2.0.20240229) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pandas->datasets->mindnlp==0.2.0.20240229) (2023.3.post1)\n",
      "Installing collected packages: multidict, frozenlist, yarl, async-timeout, aiosignal, dill, aiohttp, xxhash, pyarrow-hotfix, pyarrow, multiprocess, tokenizers, safetensors, ml-dtypes, datasets, mindnlp\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.7\n",
      "    Uninstalling dill-0.3.7:\n",
      "      Successfully uninstalled dill-0.3.7\n",
      "Successfully installed aiohttp-3.9.3 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.18.0 dill-0.3.8 frozenlist-1.4.1 mindnlp-0.2.0.20240229 ml-dtypes-0.4.0 multidict-6.0.5 multiprocess-0.70.16 pyarrow-15.0.2 pyarrow-hotfix-0.6 safetensors-0.4.2 tokenizers-0.15.2 xxhash-3.4.1 yarl-1.9.4\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/MindSpore/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mindnlp-0.2.0.20240229-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://pip.modelarts.private.com:8888/repository/pypi/simple\n",
      "Requirement already satisfied: pip in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (21.0.1)\n",
      "Collecting pip\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/pip/24.0/pip-24.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 58.7 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.0.1\n",
      "    Uninstalling pip-21.0.1:\n",
      "      Successfully uninstalled pip-21.0.1\n",
      "Successfully installed pip-24.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://pip.modelarts.private.com:8888/repository/pypi/simple\n",
      "Collecting pytest==7.2.2\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/pytest/7.2.2/pytest-7.2.2-py3-none-any.whl (317 kB)\n",
      "\u001b[K     |████████████████████████████████| 317 kB 60.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pluggy<2.0,>=0.12 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pytest==7.2.2) (1.3.0)\n",
      "Requirement already satisfied: packaging in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pytest==7.2.2) (23.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pytest==7.2.2) (23.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pytest==7.2.2) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pytest==7.2.2) (2.0.1)\n",
      "Requirement already satisfied: iniconfig in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pytest==7.2.2) (2.0.0)\n",
      "Installing collected packages: pytest\n",
      "  Attempting uninstall: pytest\n",
      "    Found existing installation: pytest 7.1.2\n",
      "    Uninstalling pytest-7.1.2:\n",
      "      Successfully uninstalled pytest-7.1.2\n",
      "Successfully installed pytest-7.2.2\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/MindSpore/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytest==7.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting tokenizers==0.15.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/14/cf/883acc48862589f9d54c239a9108728db5b75cd6c0949b92c72aae8e044c/tokenizers-0.15.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 7.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from tokenizers==0.15.0) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers==0.15.0) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers==0.15.0) (4.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers==0.15.0) (2023.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers==0.15.0) (23.2)\n",
      "Requirement already satisfied: filelock in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers==0.15.0) (3.13.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers==0.15.0) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers==0.15.0) (2.27.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers==0.15.0) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers==0.15.0) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers==0.15.0) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers==0.15.0) (2.10)\n",
      "Installing collected packages: tokenizers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.2\n",
      "    Uninstalling tokenizers-0.15.2:\n",
      "      Successfully uninstalled tokenizers-0.15.2\n",
      "Successfully installed tokenizers-0.15.0\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/MindSpore/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers==0.15.0 -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "#!wget https://repo.mindspore.cn/mindspore-lab/mindnlp/daily/202402/20240229/master_20240229160016_c5444092d8cfe47d73e292f25d9a9a56fb04828a_newest/any/mindnlp-0.2.0.20240229-py3-none-any.whl\n",
    "#!pip install mindnlp-0.2.0.20240229-py3-none-any.whl\n",
    "#!pip install pytest==7.2.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集加载与处理\n",
    "\n",
    "1. 数据集加载\n",
    "\n",
    "    本次实验使用的是nlpcc2017摘要数据，内容为新闻正文及其摘要，总计50000个样本，为加快训练速度这里只选取100条数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(1308:281472967340208,MainProcess):2024-04-11-17:35:12.932.854 [mindspore/run_check/_check_version.py:357] MindSpore version 2.2.13 and Ascend AI software package (Ascend Data Center Solution)version 7.0 does not match, the version of software package expect one of ['7.1']. Please refer to the match info on: https://www.mindspore.cn/install\n",
      "/usr/local/Ascend/ascend-toolkit/7.0.RC1/python/site-packages/tbe/tvm/contrib/ccec.py:766: DeprecationWarning: invalid escape sequence \\L\n",
      "  if not dirpath.find(\"AppData\\Local\\Temp\"):\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/classifier/transdata/transdata_classifier.py:222: DeprecationWarning: invalid escape sequence \\B\n",
      "  \"\"\"\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/vector/transdata/common/graph/transdata_graph_info.py:140: DeprecationWarning: invalid escape sequence \\c\n",
      "  \"\"\"\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "[WARNING] ME(1308:281472967340208,MainProcess):2024-04-11-17:35:20.242.352 [mindspore/run_check/_check_version.py:375] MindSpore version 2.2.13 and \"te\" wheel package version 7.0 does not match. For details, refer to the installation guidelines: https://www.mindspore.cn/install\n",
      "[WARNING] ME(1308:281472967340208,MainProcess):2024-04-11-17:35:20.245.969 [mindspore/run_check/_check_version.py:382] MindSpore version 2.2.13 and \"hccl\" wheel package version 7.0 does not match. For details, refer to the installation guidelines: https://www.mindspore.cn/install\n",
      "[WARNING] ME(1308:281472967340208,MainProcess):2024-04-11-17:35:20.246.739 [mindspore/run_check/_check_version.py:396] Please pay attention to the above warning, countdown: 3\n",
      "[WARNING] ME(1308:281472967340208,MainProcess):2024-04-11-17:35:21.248.680 [mindspore/run_check/_check_version.py:396] Please pay attention to the above warning, countdown: 2\n",
      "[WARNING] ME(1308:281472967340208,MainProcess):2024-04-11-17:35:22.251.227 [mindspore/run_check/_check_version.py:396] Please pay attention to the above warning, countdown: 1\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if _ is not 1:\n",
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 1.343 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/Cython/Compiler/Main.py:384: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindnlp/transformers/models/graphormer/algos_graphormer.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "In file included from /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h:1960:0,\n",
      "                 from /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h:12,\n",
      "                 from /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h:5,\n",
      "                 from /home/ma-user/.pyxbld/temp.linux-aarch64-cpython-39/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindnlp/transformers/models/graphormer/algos_graphormer.c:1167:\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: warning: #warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-Wcpp]\n",
      " #warning \"Using deprecated NumPy API, disable it with \" \\\n",
      "  ^~~~~~~\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件存在!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from mindnlp.utils import http_get\n",
    "\n",
    "path = \"./train_with_summ.txt\"\n",
    "if os.path.exists(path):  \n",
    "    print(\"文件存在!\")  \n",
    "else:  \n",
    "    url = 'https://download.mindspore.cn/toolkits/mindnlp/dataset/text_generation/nlpcc2017/train_with_summ.txt'\n",
    "    path = http_get(url, './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mindspore.dataset import TextFileDataset\n",
    "\n",
    "# dataset = TextFileDataset(str(path), shuffle=False)\n",
    "dataset = TextFileDataset(str(path), num_samples=100, shuffle=False)\n",
    "dataset.get_dataset_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = dataset.split([0.9, 0.1], randomize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "2. 数据预处理\n",
    "\n",
    "    原始数据格式：\n",
    "    ```text\n",
    "    article: [CLS] article_context [SEP]\n",
    "    summary: [CLS] summary_context [SEP]\n",
    "    ```\n",
    "    预处理后的数据格式：\n",
    "\n",
    "    ```text\n",
    "    [CLS] article_context [SEP] summary_context [SEP]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def process_dataset(dataset, tokenizer, batch_size=6, max_seq_len=1024, shuffle=False):\n",
    "    def read_map(text):\n",
    "        data = json.loads(text.tobytes())\n",
    "        return np.array(data['article']), np.array(data['summarization'])\n",
    "\n",
    "    def merge_and_pad(article, summary):\n",
    "        tokenized = tokenizer(text=article, text_pair=summary,\n",
    "                              padding='max_length', truncation='only_first', max_length=max_seq_len)\n",
    "        return tokenized['input_ids'], tokenized['input_ids']\n",
    "    \n",
    "    dataset = dataset.map(read_map, 'text', ['article', 'summary'])\n",
    "    dataset = dataset.map(merge_and_pad, ['article', 'summary'], ['input_ids', 'labels'])\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(batch_size)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mindnlp.transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因GPT2无中文的tokenizer，我们使用BertTokenizer替代。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = process_dataset(train_dataset, tokenizer, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tensor(shape=[4, 1024], dtype=Int64, value=\n",
       " [[ 101, 1724, 3862 ...    0,    0,    0],\n",
       "  [ 101,  704, 3173 ...    0,    0,    0],\n",
       "  [ 101, 1079, 2159 ... 1745, 8021,  102],\n",
       "  [ 101, 1355, 2357 ...    0,    0,    0]]),\n",
       " Tensor(shape=[4, 1024], dtype=Int64, value=\n",
       " [[ 101, 1724, 3862 ...    0,    0,    0],\n",
       "  [ 101,  704, 3173 ...    0,    0,    0],\n",
       "  [ 101, 1079, 2159 ... 1745, 8021,  102],\n",
       "  [ 101, 1355, 2357 ...    0,    0,    0]])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dataset.create_tuple_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21128"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型构建\n",
    "\n",
    "1. 构建GPT2ForSummarization模型，注意***shift right***的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import ops\n",
    "from mindnlp.transformers import GPT2LMHeadModel\n",
    "\n",
    "class GPT2ForSummarization(GPT2LMHeadModel):\n",
    "    def construct(\n",
    "        self,\n",
    "        input_ids = None,\n",
    "        attention_mask = None,\n",
    "        labels = None,\n",
    "    ):\n",
    "        outputs = super().construct(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        shift_logits = outputs.logits[..., :-1, :]\n",
    "        shift_labels = labels[..., 1:]\n",
    "        # Flatten the tokens\n",
    "        loss = ops.cross_entropy(shift_logits.view(-1, shift_logits.shape[-1]), shift_labels.view(-1), ignore_index=tokenizer.pad_token_id)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 设置动态学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import ops\n",
    "from mindspore.nn.learning_rate_schedule import LearningRateSchedule\n",
    "\n",
    "class LinearWithWarmUp(LearningRateSchedule):\n",
    "    \"\"\"\n",
    "    Warmup-decay learning rate.\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate, num_warmup_steps, num_training_steps):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_warmup_steps = num_warmup_steps\n",
    "        self.num_training_steps = num_training_steps\n",
    "\n",
    "    def construct(self, global_step):\n",
    "        if global_step < self.num_warmup_steps:\n",
    "            return global_step / float(max(1, self.num_warmup_steps)) * self.learning_rate\n",
    "        return ops.maximum(\n",
    "            0.0, (self.num_training_steps - global_step) / (max(1, self.num_training_steps - self.num_warmup_steps))\n",
    "        ) * self.learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练\n",
    "\n",
    "设置模型训练相关参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "warmup_steps = 20\n",
    "learning_rate = 1.5e-4\n",
    "\n",
    "num_training_steps = num_epochs * train_dataset.get_dataset_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mindspore import nn\n",
    "from mindnlp.transformers import GPT2Config, GPT2LMHeadModel\n",
    "\n",
    "config = GPT2Config(vocab_size=len(tokenizer))\n",
    "model = GPT2ForSummarization(config)\n",
    "\n",
    "lr_scheduler = LinearWithWarmUp(learning_rate=learning_rate, num_warmup_steps=warmup_steps, num_training_steps=num_training_steps)\n",
    "optimizer = nn.AdamWeightDecay(model.trainable_params(), learning_rate=lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of model parameters: 102068736\n"
     ]
    }
   ],
   "source": [
    "# 记录模型参数数量\n",
    "print('number of model parameters: {}'.format(model.num_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use 'StaticLossScaler' with `scale_value=2 ** 10` when `loss_scaler` is None.\n"
     ]
    }
   ],
   "source": [
    "from mindnlp.engine import Trainer\n",
    "from mindnlp.engine.callbacks import CheckpointCallback\n",
    "\n",
    "ckpoint_cb = CheckpointCallback(save_path='checkpoint', ckpt_name='gpt2_summarization',\n",
    "                                epochs=1, keep_checkpoint_max=2)\n",
    "\n",
    "trainer = Trainer(network=model, train_dataset=train_dataset,\n",
    "                  epochs=1, optimizer=optimizer, callbacks=ckpoint_cb)\n",
    "trainer.set_amp(level='O1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train will start from the checkpoint saved in 'checkpoint'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/23 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\r"
     ]
    }
   ],
   "source": [
    "trainer.run(tgt_columns=\"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型推理\n",
    "\n",
    "数据处理，将向量数据变为中文数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_test_dataset(dataset, tokenizer, batch_size=1, max_seq_len=1024, max_summary_len=100):\n",
    "    def read_map(text):\n",
    "        data = json.loads(text.tobytes())\n",
    "        return np.array(data['article']), np.array(data['summarization'])\n",
    "\n",
    "    def pad(article):\n",
    "        tokenized = tokenizer(text=article, truncation=True, max_length=max_seq_len-max_summary_len)\n",
    "        return tokenized['input_ids']\n",
    "\n",
    "    dataset = dataset.map(read_map, 'text', ['article', 'summary'])\n",
    "    dataset = dataset.map(pad, 'article', ['input_ids'])\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batched_test_dataset = process_test_dataset(test_dataset, tokenizer, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 101, 3173, 1290, 5381, 1266,  776,  128, 3299, 8176, 3189, 4510,\n",
      "         133,  100,  135, 2945, 3173, 1290, 4852,  100, 3173, 1290, 1744,\n",
      "        7354,  100, 2145, 2787, 4999, 2845, 6887, 8024, 2945, 7350, 5468,\n",
      "        6979,  517, 3862, 3968, 3173, 7319, 2845,  518, 8162, 3189, 2845,\n",
      "        6887, 8024, 6832, 2876, 6356, 3175, 3189, 1184, 4788, 5815,  749,\n",
      "         671,  702, 4507,  127, 1399,  704, 1744, 5093, 4511, 2094, 5299,\n",
      "        2768, 4638, 1057, 2147, 4668, 4961, 1730,  832, 8024,  800,  812,\n",
      "        1762,  791, 2399,  127, 3299, 5635,  128, 3299, 7313,  754, 6832,\n",
      "        2876,  510, 7350, 2357, 2799, 3683,  510, 3763, 6830, 5023, 6979,\n",
      "        7270, 1744, 4638, 1166, 1863, 1079, 4556, 4312,  868, 3428, 5276,\n",
      "        8203, 6629, 8024, 4668, 4961, 4403, 2140,  510, 1399, 6134,  510,\n",
      "        4385, 7032, 5023, 6586, 7028, 6568, 4289, 2600,  817,  966, 6809,\n",
      "        3144, 4636,  674, 6832, 2861, 1990, 8020,  122, 6832, 2861, 1990,\n",
      "        5276, 1394,  122, 8026,  128, 1039,  782, 3696, 2355, 8021,  511,\n",
      "        6832, 2876, 6356, 2175, 2229, 2600, 7270, 1506, 5101, 3172,  792,\n",
      "        5305, 6432, 8024, 4507,  754, 7574, 5246, 2970, 1168, 1927, 4961,\n",
      "        2845, 3428,  684, 1355, 4385,  868, 3428, 2797, 3667, 6818,  849,\n",
      "        8024, 6356, 3175, 1217, 2487,  749, 1762, 4685, 1068, 1166, 1863,\n",
      "        1277, 4638, 2337, 6872, 8024, 7219, 2137,  749,  697, 1399, 5307,\n",
      "        2382, 1286, 1915, 1400, 1762, 7353, 6818, 3952, 5782, 4638,  704,\n",
      "        1744, 5093, 4542, 4306, 8024,  794,  800,  812, 6716,  677, 3017,\n",
      "        1139, 4500,  754,  868, 3428, 4638, 3063, 7305, 2339, 1072, 1469,\n",
      "        2797, 1947,  511, 5307, 6814, 2144, 6380, 8024, 6356, 3175, 7556,\n",
      "        5972, 3043, 4478, 1762, 6832, 2876, 1290,  782, 5471, 2233, 1277,\n",
      "        1744, 7354, 1814, 1062, 2171, 1079, 6866, 2936,  749, 6421, 4668,\n",
      "        4961, 1730,  832, 4638, 1071,  800, 2768, 1447,  511, 6566, 6569,\n",
      "        1152,  903,  752, 1218, 4638, 2229, 7270, 1221, 4415, 1506, 1164,\n",
      "        1239, 6432, 8024, 6356, 3175, 1762, 6421, 1730,  832, 5966, 6716,\n",
      "        4638, 1062, 2171, 1079, 5373, 5815, 1920, 7030, 6158, 4668, 6568,\n",
      "        4289, 8024,  809, 1350,  800,  812, 5313, 1169, 4638, 6369, 1153,\n",
      "         982, 4961, 4638, 7350, 5468, 6979, 7770, 3440,  857, 2125, 1277,\n",
      "        1146, 2357, 1745,  511, 6421, 1730,  832, 6820,  897, 6371, 2199,\n",
      "        2523, 1914, 6597, 4289, 1813, 5966, 1762, 7987, 1814, 1469, 7716,\n",
      "        1046, 1745, 1990, 3322, 1767, 7353, 6818, 4638, 3763, 4030, 1765,\n",
      "        2372,  511, 4680, 1184, 6821, 8034, 1399, 4306, 5389, 1146, 2094,\n",
      "        2347, 6158, 4919,  769, 3466, 3175,  511,  102]], dtype=int64), array(['6名中国人在迪拜一个月疯狂盗窃70起，含珠宝、名表、现金等，案值数百万元；已在迪拜落网。'], dtype='<U44')]\n"
     ]
    }
   ],
   "source": [
    "print(next(batched_test_dataset.create_tuple_iterator(output_numpy=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generation config file not found, using a generation config created from the model config.\n"
     ]
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('./checkpoint/gpt2_summarization_epoch_0.ckpt', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.set_train(False)\n",
    "model.config.eos_token_id = model.config.sep_token_id\n",
    "i = 0\n",
    "for (input_ids, raw_summary) in batched_test_dataset.create_tuple_iterator():\n",
    "    output_ids = model.generate(input_ids, max_new_tokens=50, num_beams=5, no_repeat_ngram_size=2)\n",
    "    output_text = tokenizer.decode(output_ids[0].tolist())\n",
    "    print(output_text)\n",
    "    i += 1\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
